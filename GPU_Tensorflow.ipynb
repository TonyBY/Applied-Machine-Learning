{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "constitutional-circus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version:  2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib \n",
    "import os\n",
    "\n",
    "print(\"tensorflow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "furnished-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aggregate-archive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8136725461553191796\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 677824512853254939\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17680274397561958438\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17970889114200527224\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:2\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13354899726441514505\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:3\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1288837644030236673\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10556126016\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1052291985581852924\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:19:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10556126016\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8413737419234289231\n",
      "physical_device_desc: \"device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:2\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10556126016\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6644563959018176089\n",
      "physical_device_desc: \"device: 2, name: GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:3\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10540848256\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6862253860806732504\n",
      "physical_device_desc: \"device: 3, name: GeForce RTX 2080 Ti, pci bus id: 0000:68:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beautiful-saint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num XLA_GPUs Available:  4\n",
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num XLA_GPUs Available: \", len(tf.config.list_physical_devices('XLA_GPU')))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "violent-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function(jit_compile=True)\n",
    "@tf.function(experimental_compile=True)\n",
    "def matmul(a, b):\n",
    "    tf.debugging.set_log_device_placement(True)    \n",
    "    c = tf.matmul(a, b)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "greek-principle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "c = matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices(\n",
    "    device_type=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('XLA_GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.get_visible_devices(\n",
    "    device_type=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_device_protos = device_lib.list_local_devices()\n",
    "[x.name for x in local_device_protos if x.device_type == 'XLA_GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "try:\n",
    "  # Specify an invalid GPU device\n",
    "  with tf.device('/device:XLA_GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-singapore",
   "metadata": {},
   "source": [
    "# Use XLA with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-price",
   "metadata": {},
   "source": [
    "### This tutorial trains a TensorFlow model to classify the MNIST dataset, where the training function is compiled using XLA.\n",
    "\n",
    "### First, load TensorFlow and enable eager execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In TF 2.4 jit_compile is called experimental_compile\n",
    "# pip install -q tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-destiny",
   "metadata": {},
   "source": [
    "### Then define some necessary constants and prepare the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of each input image, 28 x 28 pixels\n",
    "IMAGE_SIZE = 28 * 28\n",
    "# Number of distinct number labels, [0..9]\n",
    "NUM_CLASSES = 10\n",
    "# Number of examples in each training batch (step)\n",
    "TRAIN_BATCH_SIZE = 100\n",
    "# Number of training steps to run\n",
    "TRAIN_STEPS = 1000\n",
    "\n",
    "# Loads MNIST dataset.\n",
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train).batch(TRAIN_BATCH_SIZE).repeat()\n",
    "\n",
    "# Casting from raw data to the required datatypes.\n",
    "def cast(images, labels):\n",
    "    images = tf.cast(\n",
    "      tf.reshape(images, [-1, IMAGE_SIZE]), tf.float32)\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-nursery",
   "metadata": {},
   "source": [
    "### Finally, define the model and the optimizer. The model uses a single dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(NUM_CLASSES)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-producer",
   "metadata": {},
   "source": [
    "## Define the training function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-overall",
   "metadata": {},
   "source": [
    "### In the training function, you get the predicted labels using the layer defined above, and then minimize the gradient of the loss using the optimizer. In order to compile the computation using XLA, place it inside tf.function with jit_compile=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_compile=True)\n",
    "def train_mnist(images, labels):\n",
    "    images, labels = cast(images, labels)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted_labels = layer(images)\n",
    "        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "          logits=predicted_labels, labels=labels\n",
    "        ))\n",
    "        layer_variables = layer.trainable_variables\n",
    "        grads = tape.gradient(loss, layer_variables)\n",
    "        optimizer.apply_gradients(zip(grads, layer_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-brave",
   "metadata": {},
   "source": [
    "## Train and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-fifty",
   "metadata": {},
   "source": [
    "### Once you have defined the training function, define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds:\n",
    "    if optimizer.iterations > TRAIN_STEPS:\n",
    "        break\n",
    "    train_mnist(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-window",
   "metadata": {},
   "source": [
    "### And, finally, check the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = cast(test[0], test[1])\n",
    "predicted_labels = layer(images)\n",
    "correct_prediction = tf.equal(tf.argmax(predicted_labels, 1), labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Prediction accuracy after training: %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-clearing",
   "metadata": {},
   "source": [
    "### Behind the scenes, the XLA compiler has compiled the entire TF function to HLO, which has enabled fusion optimizations. Using the introspection facilities, we can see the HLO code (other interesting possible values for \"stage\" are optimized_hlo for HLO after optimizations and optimized_hlo_dot for a Graphviz graph):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_mnist.experimental_get_compiler_ir(images, labels)(stage='hlo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-mother",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-integer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "induced-sunday",
   "metadata": {},
   "source": [
    "# XLA autoclustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-witch",
   "metadata": {},
   "source": [
    "## Classifying CIFAR-10 with XLA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-creek",
   "metadata": {},
   "source": [
    "### This tutorial trains a TensorFlow model to classify the CIFAR-10 dataset, and we compile it using XLA.\n",
    "\n",
    "### Load and normalize the dataset using the Keras API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# # Check that GPU is available: cf. https://colab.research.google.com/notebooks/gpu.ipynb\n",
    "# assert(tf.test.gpu_device_name())\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(False) # Start with XLA disabled.\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype('float32') / 256\n",
    "    x_test = x_test.astype('float32') / 256\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "    return ((x_train, y_train), (x_test, y_test))\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-motel",
   "metadata": {},
   "source": [
    "### We define the model, adapted from the Keras CIFAR-10 example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Activation('softmax')\n",
    "    ])\n",
    "\n",
    "model = generate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-finish",
   "metadata": {},
   "source": [
    "### We train the model using the RMSprop optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = compile_model(model)\n",
    "\n",
    "def train_model(model, x_train, y_train, x_test, y_test, epochs=25):\n",
    "    model.fit(x_train, y_train, batch_size=256, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "\n",
    "def warmup(model, x_train, y_train, x_test, y_test):\n",
    "    # Warm up the JIT, we do not wish to measure the compilation time.\n",
    "    initial_weights = model.get_weights()\n",
    "    train_model(model, x_train, y_train, x_test, y_test, epochs=1)\n",
    "    model.set_weights(initial_weights)\n",
    "\n",
    "warmup(model, x_train, y_train, x_test, y_test)\n",
    "%time train_model(model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-redhead",
   "metadata": {},
   "source": [
    "### Now let's train the model again, using the XLA compiler. To enable the compiler in the middle of the application, we need to reset the Keras session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to clear the session to enable JIT in the middle of the program.\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(True) # Enable XLA.\n",
    "model = compile_model(generate_model())\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "warmup(model, x_train, y_train, x_test, y_test)\n",
    "%time train_model(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-salem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-antibody",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_compile=True)\n",
    "def gpu_test():\n",
    "    sz = 25000\n",
    "    while True:\n",
    "        z = tf.math.multiply(\n",
    "    tf.random.uniform(shape=[sz]), tf.random.uniform(shape=[sz]), name=None) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'watch nvidida-smi' and htop to monitor GPU and CPU usage repectively.\n",
    "gpu_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
