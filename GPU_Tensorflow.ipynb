{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "constitutional-circus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "furnished-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aggregate-archive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12421168673629810770\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17376871065945972175\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15895756372821059687\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12422713576042441445\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:2\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 10083096500865780179\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:3\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 18307627054457248060\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beautiful-saint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num XLA_GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num XLA_GPUs Available: \", len(tf.config.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "violent-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function(jit_compile=True)\n",
    "@tf.function(experimental_compile=True)\n",
    "def matmul(a, b):\n",
    "    tf.debugging.set_log_device_placement(True)    \n",
    "    c = tf.matmul(a, b)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "greek-principle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "c = matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suitable-wilderness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acute-necklace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:2', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:3', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\n",
    "    device_type=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "certain-armor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 4\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('XLA_GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "final-cornwall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-97ecbf874269>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fifteen-saint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:2', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:3', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.get_visible_devices(\n",
    "    device_type=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "looking-yield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:XLA_GPU:0',\n",
       " '/device:XLA_GPU:1',\n",
       " '/device:XLA_GPU:2',\n",
       " '/device:XLA_GPU:3']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_device_protos = device_lib.list_local_devices()\n",
    "[x.name for x in local_device_protos if x.device_type == 'XLA_GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "suffering-phone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n",
       " LogicalDevice(name='/device:XLA_CPU:0', device_type='XLA_CPU')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chubby-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "try:\n",
    "  # Specify an invalid GPU device\n",
    "  with tf.device('/device:XLA_GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-singapore",
   "metadata": {},
   "source": [
    "# Use XLA with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-price",
   "metadata": {},
   "source": [
    "### This tutorial trains a TensorFlow model to classify the MNIST dataset, where the training function is compiled using XLA.\n",
    "\n",
    "### First, load TensorFlow and enable eager execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "roman-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In TF 2.4 jit_compile is called experimental_compile\n",
    "# pip install -q tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "relative-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-destiny",
   "metadata": {},
   "source": [
    "### Then define some necessary constants and prepare the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "amazing-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of each input image, 28 x 28 pixels\n",
    "IMAGE_SIZE = 28 * 28\n",
    "# Number of distinct number labels, [0..9]\n",
    "NUM_CLASSES = 10\n",
    "# Number of examples in each training batch (step)\n",
    "TRAIN_BATCH_SIZE = 100\n",
    "# Number of training steps to run\n",
    "TRAIN_STEPS = 1000\n",
    "\n",
    "# Loads MNIST dataset.\n",
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train).batch(TRAIN_BATCH_SIZE).repeat()\n",
    "\n",
    "# Casting from raw data to the required datatypes.\n",
    "def cast(images, labels):\n",
    "    images = tf.cast(\n",
    "      tf.reshape(images, [-1, IMAGE_SIZE]), tf.float32)\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-nursery",
   "metadata": {},
   "source": [
    "### Finally, define the model and the optimizer. The model uses a single dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "martial-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(NUM_CLASSES)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-producer",
   "metadata": {},
   "source": [
    "## Define the training function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-overall",
   "metadata": {},
   "source": [
    "### In the training function, you get the predicted labels using the layer defined above, and then minimize the gradient of the loss using the optimizer. In order to compile the computation using XLA, place it inside tf.function with jit_compile=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "noticed-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(jit_compile=True)\n",
    "def train_mnist(images, labels):\n",
    "    images, labels = cast(images, labels)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted_labels = layer(images)\n",
    "        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "          logits=predicted_labels, labels=labels\n",
    "        ))\n",
    "        layer_variables = layer.trainable_variables\n",
    "        grads = tape.gradient(loss, layer_variables)\n",
    "        optimizer.apply_gradients(zip(grads, layer_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-brave",
   "metadata": {},
   "source": [
    "## Train and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-fifty",
   "metadata": {},
   "source": [
    "### Once you have defined the training function, define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "still-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds:\n",
    "    if optimizer.iterations > TRAIN_STEPS:\n",
    "        break\n",
    "    train_mnist(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-window",
   "metadata": {},
   "source": [
    "### And, finally, check the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "important-heather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy after training: tf.Tensor(0.8789, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "images, labels = cast(test[0], test[1])\n",
    "predicted_labels = layer(images)\n",
    "correct_prediction = tf.equal(tf.argmax(predicted_labels, 1), labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Prediction accuracy after training: %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-clearing",
   "metadata": {},
   "source": [
    "### Behind the scenes, the XLA compiler has compiled the entire TF function to HLO, which has enabled fusion optimizations. Using the introspection facilities, we can see the HLO code (other interesting possible values for \"stage\" are optimized_hlo for HLO after optimizations and optimized_hlo_dot for a Graphviz graph):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "realistic-description",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HloModule a_inference_train_mnist_5302__.205, input_output_alias={ {0}: (2, {}, may-alias), {1}: (3, {}, may-alias), {2}: (5, {}, may-alias), {3}: (8, {}, may-alias), {4}: (9, {}, may-alias), {5}: (10, {}, may-alias), {6}: (11, {}, may-alias) }\n",
      "\n",
      "%max_float_.64 (x.65: f32[], y.66: f32[]) -> f32[] {\n",
      "  %x.65 = f32[] parameter(0)\n",
      "  %y.66 = f32[] parameter(1)\n",
      "  ROOT %maximum.67 = f32[] maximum(f32[] %x.65, f32[] %y.66)\n",
      "}\n",
      "\n",
      "%add_float_.74 (x.75: f32[], y.76: f32[]) -> f32[] {\n",
      "  %x.75 = f32[] parameter(0)\n",
      "  %y.76 = f32[] parameter(1)\n",
      "  ROOT %add.77 = f32[] add(f32[] %x.75, f32[] %y.76)\n",
      "}\n",
      "\n",
      "%add_float_.93 (x.94: f32[], y.95: f32[]) -> f32[] {\n",
      "  %x.94 = f32[] parameter(0)\n",
      "  %y.95 = f32[] parameter(1)\n",
      "  ROOT %add.96 = f32[] add(f32[] %x.94, f32[] %y.95)\n",
      "}\n",
      "\n",
      "%Mean-reduction.105 (x.106: f32[], y.107: f32[]) -> f32[] {\n",
      "  %x.106 = f32[] parameter(0)\n",
      "  %y.107 = f32[] parameter(1)\n",
      "  ROOT %add.108 = f32[] add(f32[] %x.106, f32[] %y.107)\n",
      "}\n",
      "\n",
      "%add_float_.123 (x.124: f32[], y.125: f32[]) -> f32[] {\n",
      "  %x.124 = f32[] parameter(0)\n",
      "  %y.125 = f32[] parameter(1)\n",
      "  ROOT %add.126 = f32[] add(f32[] %x.124, f32[] %y.125)\n",
      "}\n",
      "\n",
      "ENTRY %a_inference_train_mnist_5302__.205 (arg0.1: f32[10000,784], arg1.2: s64[10000], arg2.3: f32[784,10], arg3.4: f32[10], arg4.5: f32[], arg5.6: s64[], arg6.7: f32[], arg7.8: f32[], arg8.9: f32[784,10], arg9.10: f32[784,10], arg10.11: f32[10], arg11.12: f32[10]) -> (f32[784,10], f32[10], s64[], f32[784,10], f32[784,10], /*index=5*/f32[10], f32[10]) {\n",
      "  %constant.15 = f32[] constant(1), metadata={op_type=\"Sub\" op_name=\"Adam/sub_2\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=148}\n",
      "  %constant.16 = f32[] constant(1), metadata={op_type=\"Sub\" op_name=\"Adam/sub_2\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=148}\n",
      "  %arg6.7 = f32[] parameter(6), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  %subtract.17 = f32[] subtract(f32[] %constant.16, f32[] %arg6.7), metadata={op_type=\"Sub\" op_name=\"Adam/sub_2\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=148}\n",
      "  %constant.18 = f32[] constant(1), metadata={op_type=\"Sub\" op_name=\"Adam/sub_3\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=151}\n",
      "  %constant.19 = f32[] constant(1), metadata={op_type=\"Sub\" op_name=\"Adam/sub_3\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=151}\n",
      "  %arg7.8 = f32[] parameter(7), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  %subtract.20 = f32[] subtract(f32[] %constant.19, f32[] %arg7.8), metadata={op_type=\"Sub\" op_name=\"Adam/sub_3\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=151}\n",
      "  %constant.21 = s64[] constant(1), metadata={op_type=\"AddV2\" op_name=\"Adam/add\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=134}\n",
      "  %constant.26 = f32[] constant(1), metadata={op_type=\"Sub\" op_name=\"Adam/sub_1\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=140}\n",
      "  %constant.30 = f32[] constant(1), metadata={op_type=\"Sub\" op_name=\"Adam/sub\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=140}\n",
      "  %arg4.5 = f32[] parameter(4), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  %constant.31 = f32[] constant(1), metadata={op_type=\"Sub\" op_name=\"Adam/sub\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=140}\n",
      "  %arg5.6 = s64[] parameter(5), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  %constant.22 = s64[] constant(1), metadata={op_type=\"AddV2\" op_name=\"Adam/add\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=134}\n",
      "  %add.23 = s64[] add(s64[] %arg5.6, s64[] %constant.22), metadata={op_type=\"AddV2\" op_name=\"Adam/add\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=134}\n",
      "  %convert.24 = f32[] convert(s64[] %add.23), metadata={op_type=\"Cast\" op_name=\"Adam/Cast_1\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=134}\n",
      "  %power.29 = f32[] power(f32[] %arg7.8, f32[] %convert.24), metadata={op_type=\"Pow\" op_name=\"Adam/Pow_1\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=138}\n",
      "  %subtract.32 = f32[] subtract(f32[] %constant.31, f32[] %power.29), metadata={op_type=\"Sub\" op_name=\"Adam/sub\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=140}\n",
      "  %sqrt.33 = f32[] sqrt(f32[] %subtract.32), metadata={op_type=\"Sqrt\" op_name=\"Adam/Sqrt\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=140}\n",
      "  %constant.27 = f32[] constant(1), metadata={op_type=\"Sub\" op_name=\"Adam/sub_1\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=140}\n",
      "  %power.25 = f32[] power(f32[] %arg6.7, f32[] %convert.24), metadata={op_type=\"Pow\" op_name=\"Adam/Pow\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=137}\n",
      "  %subtract.28 = f32[] subtract(f32[] %constant.27, f32[] %power.25), metadata={op_type=\"Sub\" op_name=\"Adam/sub_1\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=140}\n",
      "  %divide.34 = f32[] divide(f32[] %sqrt.33, f32[] %subtract.28), metadata={op_type=\"RealDiv\" op_name=\"Adam/truediv\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=140}\n",
      "  %multiply.35 = f32[] multiply(f32[] %arg4.5, f32[] %divide.34), metadata={op_type=\"Mul\" op_name=\"Adam/mul\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=139}\n",
      "  %arg1.2 = s64[10000]{0} parameter(1), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  %reshape.14 = s64[10000]{0} reshape(s64[10000]{0} %arg1.2)\n",
      "  %broadcast.46 = s64[10000,10]{1,0} broadcast(s64[10000]{0} %reshape.14), dimensions={0}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %iota.45 = s64[10000,10]{1,0} iota(), iota_dimension=1, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %compare.47 = pred[10000,10]{1,0} compare(s64[10000,10]{1,0} %broadcast.46, s64[10000,10]{1,0} %iota.45), direction=EQ, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.42 = f32[] constant(1), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %broadcast.44 = f32[10000,10]{1,0} broadcast(f32[] %constant.42), dimensions={}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.41 = f32[] constant(0), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %broadcast.43 = f32[10000,10]{1,0} broadcast(f32[] %constant.41), dimensions={}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %select.48 = f32[10000,10]{1,0} select(pred[10000,10]{1,0} %compare.47, f32[10000,10]{1,0} %broadcast.44, f32[10000,10]{1,0} %broadcast.43), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.56 = s64[] constant(0), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %broadcast.57 = s64[10000]{0} broadcast(s64[] %constant.56), dimensions={}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %compare.58 = pred[10000]{0} compare(s64[10000]{0} %broadcast.57, s64[10000]{0} %reshape.14), direction=LE, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.53 = s64[] constant(10), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %broadcast.54 = s64[10000]{0} broadcast(s64[] %constant.53), dimensions={}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %compare.55 = pred[10000]{0} compare(s64[10000]{0} %reshape.14, s64[10000]{0} %broadcast.54), direction=LT, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %and.59 = pred[10000]{0} and(pred[10000]{0} %compare.58, pred[10000]{0} %compare.55), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.51 = f32[] constant(0), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %broadcast.52 = f32[10000]{0} broadcast(f32[] %constant.51), dimensions={}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.49 = f32[] constant(nan), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %broadcast.50 = f32[10000]{0} broadcast(f32[] %constant.49), dimensions={}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %select.60 = f32[10000]{0} select(pred[10000]{0} %and.59, f32[10000]{0} %broadcast.52, f32[10000]{0} %broadcast.50), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %broadcast.61 = f32[10000,10]{1,0} broadcast(f32[10000]{0} %select.60), dimensions={0}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %add.62 = f32[10000,10]{1,0} add(f32[10000,10]{1,0} %select.48, f32[10000,10]{1,0} %broadcast.61), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %negate.89 = f32[10000,10]{1,0} negate(f32[10000,10]{1,0} %add.62), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.85 = f32[] constant(0), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %broadcast.86 = f32[10000,10]{1,0} broadcast(f32[] %constant.85), dimensions={}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %compare.87 = pred[10000,10]{1,0} compare(f32[10000,10]{1,0} %add.62, f32[10000,10]{1,0} %broadcast.86), direction=EQ, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.83 = f32[] constant(0), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %broadcast.84 = f32[10000,10]{1,0} broadcast(f32[] %constant.83), dimensions={}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %arg0.1 = f32[10000,784]{1,0} parameter(0), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  %reshape.13 = f32[10000,784]{1,0} reshape(f32[10000,784]{1,0} %arg0.1)\n",
      "  %reshape.36 = f32[10000,784]{1,0} reshape(f32[10000,784]{1,0} %reshape.13), metadata={op_type=\"Reshape\" op_name=\"Reshape\" source_file=\"<ipython-input-18-f1ea40603bad>\" source_line=16}\n",
      "  %arg2.3 = f32[784,10]{1,0} parameter(2), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  %dot.37 = f32[10000,10]{1,0} dot(f32[10000,784]{1,0} %reshape.36, f32[784,10]{1,0} %arg2.3), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type=\"MatMul\" op_name=\"dense/MatMul\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\" source_line=1242}\n",
      "  %transpose.38 = f32[10000,10]{1,0} transpose(f32[10000,10]{1,0} %dot.37), dimensions={0,1}, metadata={op_type=\"MatMul\" op_name=\"dense/MatMul\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\" source_line=1242}\n",
      "  %arg3.4 = f32[10]{0} parameter(3), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  %broadcast.39 = f32[10000,10]{1,0} broadcast(f32[10]{0} %arg3.4), dimensions={1}, metadata={op_type=\"BiasAdd\" op_name=\"dense/BiasAdd\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\" source_line=1253}\n",
      "  %add.40 = f32[10000,10]{1,0} add(f32[10000,10]{1,0} %transpose.38, f32[10000,10]{1,0} %broadcast.39), metadata={op_type=\"BiasAdd\" op_name=\"dense/BiasAdd\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\" source_line=1253}\n",
      "  %constant.63 = f32[] constant(-inf), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %reduce.68 = f32[10000]{0} reduce(f32[10000,10]{1,0} %add.40, f32[] %constant.63), dimensions={1}, to_apply=%max_float_.64, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %broadcast.69 = f32[10000,10]{1,0} broadcast(f32[10000]{0} %reduce.68), dimensions={0}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %subtract.70 = f32[10000,10]{1,0} subtract(f32[10000,10]{1,0} %add.40, f32[10000,10]{1,0} %broadcast.69), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %exponential.71 = f32[10000,10]{1,0} exponential(f32[10000,10]{1,0} %subtract.70), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %convert.72 = f32[10000,10]{1,0} convert(f32[10000,10]{1,0} %exponential.71), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.73 = f32[] constant(0), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %reduce.78 = f32[10000]{0} reduce(f32[10000,10]{1,0} %convert.72, f32[] %constant.73), dimensions={1}, to_apply=%add_float_.74, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %convert.79 = f32[10000]{0} convert(f32[10000]{0} %reduce.78), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %log.80 = f32[10000]{0} log(f32[10000]{0} %convert.79), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %broadcast.81 = f32[10000,10]{1,0} broadcast(f32[10000]{0} %log.80), dimensions={0}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %subtract.82 = f32[10000,10]{1,0} subtract(f32[10000,10]{1,0} %subtract.70, f32[10000,10]{1,0} %broadcast.81), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %select.88 = f32[10000,10]{1,0} select(pred[10000,10]{1,0} %compare.87, f32[10000,10]{1,0} %broadcast.84, f32[10000,10]{1,0} %subtract.82), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %multiply.90 = f32[10000,10]{1,0} multiply(f32[10000,10]{1,0} %negate.89, f32[10000,10]{1,0} %select.88), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %convert.92 = f32[10000,10]{1,0} convert(f32[10000,10]{1,0} %multiply.90), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.91 = f32[] constant(0), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %reduce.97 = f32[10000]{0} reduce(f32[10000,10]{1,0} %convert.92, f32[] %constant.91), dimensions={1}, to_apply=%add_float_.93, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %convert.98 = f32[10000]{0} convert(f32[10000]{0} %reduce.97), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %convert.102 = f32[10000]{0} convert(f32[10000]{0} %convert.98), metadata={op_type=\"Mean\" op_name=\"Mean\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.103 = f32[] constant(0), metadata={op_type=\"Mean\" op_name=\"Mean\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %convert.104 = f32[] convert(f32[] %constant.103), metadata={op_type=\"Mean\" op_name=\"Mean\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %reduce.109 = f32[] reduce(f32[10000]{0} %convert.102, f32[] %convert.104), dimensions={0}, to_apply=%Mean-reduction.105, metadata={op_type=\"Mean\" op_name=\"Mean\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.110 = s32[] constant(10000), metadata={op_type=\"Mean\" op_name=\"Mean\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %convert.111 = f32[] convert(s32[] %constant.110), metadata={op_type=\"Mean\" op_name=\"Mean\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %divide.112 = f32[] divide(f32[] %reduce.109, f32[] %convert.111), metadata={op_type=\"Mean\" op_name=\"Mean\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %convert.113 = f32[] convert(f32[] %divide.112), metadata={op_type=\"Mean\" op_name=\"Mean\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %constant.114 = f32[] constant(0.0001), metadata={op_type=\"Mul\" op_name=\"gradient_tape/SparseSoftmaxCrossEntropyWithLogits/mul\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %broadcast.115 = f32[10000,1]{1,0} broadcast(f32[] %constant.114), dimensions={}, metadata={op_type=\"Mul\" op_name=\"gradient_tape/SparseSoftmaxCrossEntropyWithLogits/mul\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %arg8.9 = f32[784,10]{1,0} parameter(8), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  %constant.116 = f32[] constant(0.0001), metadata={op_type=\"Mul\" op_name=\"gradient_tape/SparseSoftmaxCrossEntropyWithLogits/mul\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %broadcast.117 = f32[10000,1]{1,0} broadcast(f32[] %constant.116), dimensions={}, metadata={op_type=\"Mul\" op_name=\"gradient_tape/SparseSoftmaxCrossEntropyWithLogits/mul\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %reshape.118 = f32[10000]{0} reshape(f32[10000,1]{1,0} %broadcast.117), metadata={op_type=\"Mul\" op_name=\"gradient_tape/SparseSoftmaxCrossEntropyWithLogits/mul\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %broadcast.119 = f32[10000,10]{1,0} broadcast(f32[10000]{0} %reshape.118), dimensions={0}, metadata={op_type=\"Mul\" op_name=\"gradient_tape/SparseSoftmaxCrossEntropyWithLogits/mul\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %broadcast.99 = f32[10000,10]{1,0} broadcast(f32[10000]{0} %convert.79), dimensions={0}, metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %divide.100 = f32[10000,10]{1,0} divide(f32[10000,10]{1,0} %exponential.71, f32[10000,10]{1,0} %broadcast.99), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %subtract.101 = f32[10000,10]{1,0} subtract(f32[10000,10]{1,0} %divide.100, f32[10000,10]{1,0} %add.62), metadata={op_type=\"SparseSoftmaxCrossEntropyWithLogits\" op_name=\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=7}\n",
      "  %multiply.120 = f32[10000,10]{1,0} multiply(f32[10000,10]{1,0} %broadcast.119, f32[10000,10]{1,0} %subtract.101), metadata={op_type=\"Mul\" op_name=\"gradient_tape/SparseSoftmaxCrossEntropyWithLogits/mul\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %dot.154 = f32[784,10]{1,0} dot(f32[10000,784]{1,0} %reshape.36, f32[10000,10]{1,0} %multiply.120), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type=\"MatMul\" op_name=\"gradient_tape/dense/MatMul\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %transpose.155 = f32[784,10]{1,0} transpose(f32[784,10]{1,0} %dot.154), dimensions={0,1}, metadata={op_type=\"MatMul\" op_name=\"gradient_tape/dense/MatMul\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %subtract.164 = f32[784,10]{1,0} subtract(f32[784,10]{1,0} %transpose.155, f32[784,10]{1,0} %arg8.9), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %constant.157 = f32[] constant(1), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %subtract.163 = f32[] subtract(f32[] %constant.157, f32[] %arg6.7), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %broadcast.165 = f32[784,10]{1,0} broadcast(f32[] %subtract.163), dimensions={}, metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %multiply.166 = f32[784,10]{1,0} multiply(f32[784,10]{1,0} %subtract.164, f32[784,10]{1,0} %broadcast.165), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %add.167 = f32[784,10]{1,0} add(f32[784,10]{1,0} %arg8.9, f32[784,10]{1,0} %multiply.166), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %subtract.159 = f32[] subtract(f32[] %constant.157, f32[] %power.29), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %sqrt.160 = f32[] sqrt(f32[] %subtract.159), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %multiply.161 = f32[] multiply(f32[] %arg4.5, f32[] %sqrt.160), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %subtract.158 = f32[] subtract(f32[] %constant.157, f32[] %power.25), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %divide.162 = f32[] divide(f32[] %multiply.161, f32[] %subtract.158), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %broadcast.177 = f32[784,10]{1,0} broadcast(f32[] %divide.162), dimensions={}, metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %multiply.178 = f32[784,10]{1,0} multiply(f32[784,10]{1,0} %add.167, f32[784,10]{1,0} %broadcast.177), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %arg9.10 = f32[784,10]{1,0} parameter(9), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  %multiply.169 = f32[784,10]{1,0} multiply(f32[784,10]{1,0} %transpose.155, f32[784,10]{1,0} %transpose.155), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %subtract.170 = f32[784,10]{1,0} subtract(f32[784,10]{1,0} %multiply.169, f32[784,10]{1,0} %arg9.10), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %subtract.168 = f32[] subtract(f32[] %constant.157, f32[] %arg7.8), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %broadcast.171 = f32[784,10]{1,0} broadcast(f32[] %subtract.168), dimensions={}, metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %multiply.172 = f32[784,10]{1,0} multiply(f32[784,10]{1,0} %subtract.170, f32[784,10]{1,0} %broadcast.171), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %add.173 = f32[784,10]{1,0} add(f32[784,10]{1,0} %arg9.10, f32[784,10]{1,0} %multiply.172), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %sqrt.174 = f32[784,10]{1,0} sqrt(f32[784,10]{1,0} %add.173), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %constant.156 = f32[] constant(1e-07), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %broadcast.175 = f32[784,10]{1,0} broadcast(f32[] %constant.156), dimensions={}, metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %add.176 = f32[784,10]{1,0} add(f32[784,10]{1,0} %sqrt.174, f32[784,10]{1,0} %broadcast.175), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %divide.179 = f32[784,10]{1,0} divide(f32[784,10]{1,0} %multiply.178, f32[784,10]{1,0} %add.176), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %subtract.180 = f32[784,10]{1,0} subtract(f32[784,10]{1,0} %arg2.3, f32[784,10]{1,0} %divide.179), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %reshape.183 = f32[784,10]{1,0} reshape(f32[784,10]{1,0} %subtract.180), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %tuple.184 = (f32[784,10]{1,0}) tuple(f32[784,10]{1,0} %reshape.183), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %get-tuple-element.185 = f32[784,10]{1,0} get-tuple-element((f32[784,10]{1,0}) %tuple.184), index=0, metadata={op_name=\"XLA_Retvals\"}\n",
      "  %arg10.11 = f32[10]{0} parameter(10), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  %convert.121 = f32[10000,10]{1,0} convert(f32[10000,10]{1,0} %multiply.120), metadata={op_type=\"BiasAddGrad\" op_name=\"gradient_tape/dense/BiasAdd/BiasAddGrad\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %constant.122 = f32[] constant(0), metadata={op_type=\"BiasAddGrad\" op_name=\"gradient_tape/dense/BiasAdd/BiasAddGrad\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %reduce.127 = f32[10]{0} reduce(f32[10000,10]{1,0} %convert.121, f32[] %constant.122), dimensions={0}, to_apply=%add_float_.123, metadata={op_type=\"BiasAddGrad\" op_name=\"gradient_tape/dense/BiasAdd/BiasAddGrad\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %convert.128 = f32[10]{0} convert(f32[10]{0} %reduce.127), metadata={op_type=\"BiasAddGrad\" op_name=\"gradient_tape/dense/BiasAdd/BiasAddGrad\" source_file=\"<ipython-input-20-a4f56657032c>\" source_line=11}\n",
      "  %subtract.137 = f32[10]{0} subtract(f32[10]{0} %convert.128, f32[10]{0} %arg10.11), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %constant.130 = f32[] constant(1), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %subtract.136 = f32[] subtract(f32[] %constant.130, f32[] %arg6.7), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %broadcast.138 = f32[10]{0} broadcast(f32[] %subtract.136), dimensions={}, metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %multiply.139 = f32[10]{0} multiply(f32[10]{0} %subtract.137, f32[10]{0} %broadcast.138), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %add.140 = f32[10]{0} add(f32[10]{0} %arg10.11, f32[10]{0} %multiply.139), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %subtract.132 = f32[] subtract(f32[] %constant.130, f32[] %power.29), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %sqrt.133 = f32[] sqrt(f32[] %subtract.132), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %multiply.134 = f32[] multiply(f32[] %arg4.5, f32[] %sqrt.133), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %subtract.131 = f32[] subtract(f32[] %constant.130, f32[] %power.25), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %divide.135 = f32[] divide(f32[] %multiply.134, f32[] %subtract.131), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %broadcast.150 = f32[10]{0} broadcast(f32[] %divide.135), dimensions={}, metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %multiply.151 = f32[10]{0} multiply(f32[10]{0} %add.140, f32[10]{0} %broadcast.150), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %arg11.12 = f32[10]{0} parameter(11), parameter_replication={false}, metadata={op_name=\"XLA_Args\"}\n",
      "  %multiply.142 = f32[10]{0} multiply(f32[10]{0} %convert.128, f32[10]{0} %convert.128), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %subtract.143 = f32[10]{0} subtract(f32[10]{0} %multiply.142, f32[10]{0} %arg11.12), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %subtract.141 = f32[] subtract(f32[] %constant.130, f32[] %arg7.8), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %broadcast.144 = f32[10]{0} broadcast(f32[] %subtract.141), dimensions={}, metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %multiply.145 = f32[10]{0} multiply(f32[10]{0} %subtract.143, f32[10]{0} %broadcast.144), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %add.146 = f32[10]{0} add(f32[10]{0} %arg11.12, f32[10]{0} %multiply.145), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %sqrt.147 = f32[10]{0} sqrt(f32[10]{0} %add.146), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %constant.129 = f32[] constant(1e-07), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %broadcast.148 = f32[10]{0} broadcast(f32[] %constant.129), dimensions={}, metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %add.149 = f32[10]{0} add(f32[10]{0} %sqrt.147, f32[10]{0} %broadcast.148), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %divide.152 = f32[10]{0} divide(f32[10]{0} %multiply.151, f32[10]{0} %add.149), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %subtract.153 = f32[10]{0} subtract(f32[10]{0} %arg3.4, f32[10]{0} %divide.152), metadata={op_type=\"ResourceApplyAdam\" op_name=\"Adam/Adam/update_1/ResourceApplyAdam\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\" source_line=172}\n",
      "  %reshape.186 = f32[10]{0} reshape(f32[10]{0} %subtract.153), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %tuple.187 = (f32[10]{0}) tuple(f32[10]{0} %reshape.186), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %get-tuple-element.188 = f32[10]{0} get-tuple-element((f32[10]{0}) %tuple.187), index=0, metadata={op_name=\"XLA_Retvals\"}\n",
      "  %constant.181 = s64[] constant(1), metadata={op_type=\"AssignAddVariableOp\" op_name=\"Adam/Adam/AssignAddVariableOp\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\" source_line=717}\n",
      "  %add.182 = s64[] add(s64[] %arg5.6, s64[] %constant.181), metadata={op_type=\"AssignAddVariableOp\" op_name=\"Adam/Adam/AssignAddVariableOp\" source_file=\"/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\" source_line=717}\n",
      "  %reshape.189 = s64[] reshape(s64[] %add.182), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %tuple.190 = (s64[]) tuple(s64[] %reshape.189), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %get-tuple-element.191 = s64[] get-tuple-element((s64[]) %tuple.190), index=0, metadata={op_name=\"XLA_Retvals\"}\n",
      "  %reshape.192 = f32[784,10]{1,0} reshape(f32[784,10]{1,0} %add.167), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %tuple.193 = (f32[784,10]{1,0}) tuple(f32[784,10]{1,0} %reshape.192), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %get-tuple-element.194 = f32[784,10]{1,0} get-tuple-element((f32[784,10]{1,0}) %tuple.193), index=0, metadata={op_name=\"XLA_Retvals\"}\n",
      "  %reshape.195 = f32[784,10]{1,0} reshape(f32[784,10]{1,0} %add.173), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %tuple.196 = (f32[784,10]{1,0}) tuple(f32[784,10]{1,0} %reshape.195), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %get-tuple-element.197 = f32[784,10]{1,0} get-tuple-element((f32[784,10]{1,0}) %tuple.196), index=0, metadata={op_name=\"XLA_Retvals\"}\n",
      "  %reshape.198 = f32[10]{0} reshape(f32[10]{0} %add.140), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %tuple.199 = (f32[10]{0}) tuple(f32[10]{0} %reshape.198), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %get-tuple-element.200 = f32[10]{0} get-tuple-element((f32[10]{0}) %tuple.199), index=0, metadata={op_name=\"XLA_Retvals\"}\n",
      "  %reshape.201 = f32[10]{0} reshape(f32[10]{0} %add.146), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %tuple.202 = (f32[10]{0}) tuple(f32[10]{0} %reshape.201), metadata={op_name=\"XLA_Retvals\"}\n",
      "  %get-tuple-element.203 = f32[10]{0} get-tuple-element((f32[10]{0}) %tuple.202), index=0, metadata={op_name=\"XLA_Retvals\"}\n",
      "  ROOT %tuple.204 = (f32[784,10]{1,0}, f32[10]{0}, s64[], f32[784,10]{1,0}, f32[784,10]{1,0}, /*index=5*/f32[10]{0}, f32[10]{0}) tuple(f32[784,10]{1,0} %get-tuple-element.185, f32[10]{0} %get-tuple-element.188, s64[] %get-tuple-element.191, f32[784,10]{1,0} %get-tuple-element.194, f32[784,10]{1,0} %get-tuple-element.197, /*index=5*/f32[10]{0} %get-tuple-element.200, f32[10]{0} %get-tuple-element.203), metadata={op_name=\"XLA_Retvals\"}\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_mnist.experimental_get_compiler_ir(images, labels)(stage='hlo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-mother",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-integer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "induced-sunday",
   "metadata": {},
   "source": [
    "# XLA autoclustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-witch",
   "metadata": {},
   "source": [
    "## Classifying CIFAR-10 with XLA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-creek",
   "metadata": {},
   "source": [
    "### This tutorial trains a TensorFlow model to classify the CIFAR-10 dataset, and we compile it using XLA.\n",
    "\n",
    "### Load and normalize the dataset using the Keras API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "interracial-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# # Check that GPU is available: cf. https://colab.research.google.com/notebooks/gpu.ipynb\n",
    "# assert(tf.test.gpu_device_name())\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(False) # Start with XLA disabled.\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype('float32') / 256\n",
    "    x_test = x_test.astype('float32') / 256\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "    return ((x_train, y_train), (x_test, y_test))\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-motel",
   "metadata": {},
   "source": [
    "### We define the model, adapted from the Keras CIFAR-10 example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "explicit-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Activation('softmax')\n",
    "    ])\n",
    "\n",
    "model = generate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-finish",
   "metadata": {},
   "source": [
    "### We train the model using the RMSprop optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "religious-anger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38/196 [====>.........................] - ETA: 13s - loss: 1.8264 - accuracy: 0.3398"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-4511cb78740e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mwarmup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_model(model, x_train, y_train, x_test, y_test)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-4511cb78740e>\u001b[0m in \u001b[0;36mwarmup\u001b[0;34m(model, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Warm up the JIT, we do not wish to measure the compilation time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minitial_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-4511cb78740e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, x_train, y_train, x_test, y_test, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 _r=1):\n\u001b[1;32m   1185\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m       (graph_function,\n\u001b[1;32m   3020\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3021\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3022\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1955\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1957\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1958\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compile_model(model):\n",
    "    opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = compile_model(model)\n",
    "\n",
    "def train_model(model, x_train, y_train, x_test, y_test, epochs=25):\n",
    "    model.fit(x_train, y_train, batch_size=256, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "\n",
    "def warmup(model, x_train, y_train, x_test, y_test):\n",
    "    # Warm up the JIT, we do not wish to measure the compilation time.\n",
    "    initial_weights = model.get_weights()\n",
    "    train_model(model, x_train, y_train, x_test, y_test, epochs=1)\n",
    "    model.set_weights(initial_weights)\n",
    "\n",
    "warmup(model, x_train, y_train, x_test, y_test)\n",
    "%time train_model(model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-redhead",
   "metadata": {},
   "source": [
    "### Now let's train the model again, using the XLA compiler. To enable the compiler in the middle of the application, we need to reset the Keras session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "amino-lotus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 18s 88ms/step - loss: 2.1477 - accuracy: 0.1945 - val_loss: 1.8041 - val_accuracy: 0.3696\n",
      "Epoch 1/25\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 2.0883 - accuracy: 0.2206 - val_loss: 1.8702 - val_accuracy: 0.3479\n",
      "Epoch 2/25\n",
      " 74/196 [==========>...................] - ETA: 10s - loss: 1.8561 - accuracy: 0.3278"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-4511cb78740e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, x_train, y_train, x_test, y_test, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 _r=1):\n\u001b[1;32m   1185\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m       (graph_function,\n\u001b[1;32m   3020\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3021\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3022\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1955\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1957\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1958\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We need to clear the session to enable JIT in the middle of the program.\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(True) # Enable XLA.\n",
    "model = compile_model(generate_model())\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "warmup(model, x_train, y_train, x_test, y_test)\n",
    "%time train_model(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-salem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-antibody",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "indie-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_compile=True)\n",
    "def gpu_test():\n",
    "    sz = 25000\n",
    "    while True:\n",
    "        z = tf.math.multiply(\n",
    "    tf.random.uniform(shape=[sz]), tf.random.uniform(shape=[sz]), name=None) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "serious-compound",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b8a7a53cf821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgpu_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    927\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3046\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3047\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3048\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3049\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3441\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3442\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3275\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3277\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3278\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmp142uhrnr.py\u001b[0m in \u001b[0;36mtf__gpu_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhile_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__gpu_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mwhile_stmt\u001b[0;34m(test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m    856\u001b[0m   \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m   \u001b[0m_py_while_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_py_while_stmt\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m     \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mprotected_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0moriginal_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprotected_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0moriginal_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m       \u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmp142uhrnr.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mloop_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    307\u001b[0m           shape, minval, maxval, seed=seed1, seed2=seed2, name=name)\n\u001b[1;32m    308\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m       result = gen_random_ops.random_uniform(\n\u001b[0m\u001b[1;32m    310\u001b[0m           shape, dtype, seed=seed1, seed2=seed2)\n\u001b[1;32m    311\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mminval_is_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0mseed2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m   \u001b[0mseed2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seed2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m    738\u001b[0m         \u001b[0;34m\"RandomUniform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                          name=name)\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-3.8/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;31m# NOTE(mrry): We add an explicit colocation constraint between\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;31m# the newly created op and any of its reference-typed inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m     must_colocate_inputs = [val for arg, val in zip(op_def.input_arg, inputs)\n\u001b[0m\u001b[1;32m    744\u001b[0m                             if arg.is_ref]\n\u001b[1;32m    745\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_MaybeColocateWith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmust_colocate_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use 'watch nvidida-smi' and htop to monitor GPU and CPU usage repectively.\n",
    "gpu_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
