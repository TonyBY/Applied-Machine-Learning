{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 8: AutoEncoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your name and UFL email address\n",
    "name = 'enter your name'\n",
    "email = 'enter your email'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if name == 'enter your name' or email == 'enter your email':\n",
    "    assert False, 'Enter your name & email first!'\n",
    "else:\n",
    "    print('Assignment 8 -- name: {}, email: {}\\n'.format(name, email))\n",
    "    \n",
    "    # Load packages we need\n",
    "    import sys\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    import numpy as np\n",
    "    import sklearn\n",
    "    \n",
    "    # we'll use tensorflow and keras for neural networks\n",
    "    import tensorflow as tf\n",
    "    import tensorflow.keras as keras\n",
    "    \n",
    "    # import layers we may use\n",
    "    from tensorflow.keras.layers import Input, Flatten, Reshape, Dense, Conv2D, Conv2DTranspose, MaxPooling2D, Dropout\n",
    "\n",
    "    # import callbacks we may use\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "    \n",
    "    # Load the TensorBoard notebook extension\n",
    "    #%load_ext tensorboard\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "    # Let's check our software versions\n",
    "    print('### Python version: ' + __import__('sys').version)\n",
    "    print('### NumPy version: ' + np.__version__)\n",
    "    print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "    print('### Tensorflow version: ' + tf.__version__)\n",
    "    print('### TF Keras version: ' + keras.__version__)\n",
    "    print('------------')\n",
    "\n",
    "\n",
    "    # load our packages / code\n",
    "    sys.path.insert(1, '../common/')\n",
    "    import utils\n",
    "    import plots\n",
    "    import nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters to control behavior of the pre-processing, ML, analysis, etc.\n",
    "seed = 42\n",
    "\n",
    "# deterministic seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "prop_vec = [24, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once again we will use the MNIST data. Let's load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the data\n",
    "train_x, train_y, test_x, test_y, val_x, val_y, all_x, all_y = utils.load_preprocess_mnist_data(onehot=False, flatten=False, prop_vec=prop_vec, seed=seed)\n",
    "\n",
    "# sanity check shapes\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape, val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale so all pixel values are in the [0,1] range \n",
    "train_x = train_x / 255.0\n",
    "test_x = test_x / 255.0\n",
    "val_x = val_x / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 1] (30 points) Build a simple AutoEncoder (AE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1a] (20 points) Complete the implementation of create_simple_ae() according to the architecture and instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start by creating the encoder ('enc_model'). It should have the following architecture:\n",
    "- Flatten\n",
    "- FC with hidden_widths[0] units with activation ReLU\n",
    "- FC with hidden_widths[1] units with activation ReLU\n",
    "- FC with latent_width units with activation *sigmoid*\n",
    "\n",
    "#### Then create the decoder ('dec_model'). It should have the following architecture:\n",
    "- (Input has shape latent_width)\n",
    "- FC with hidden_widths[1] units with activation ReLU\n",
    "- FC with hidden_widths[0] units with activation ReLU\n",
    "- FC with 784 units with activation *sigmoid*\n",
    "- Reshape to input_shape\n",
    "\n",
    "#### Finally connect the two models together into a new model ('ae_model'). Make sure that the model takes the input that the encoder takes and produces the output that the decoder produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_ae(input_shape=(28, 28), latent_width=100, hidden_widths=[256, 64], verbose=False):\n",
    "    name = 'AE-simple'\n",
    "    \n",
    "    ###* put your code here (~10-20 lines) *###\n",
    "    \n",
    "    # encoder\n",
    "    \n",
    "    \n",
    "    # decoder\n",
    "       \n",
    "    \n",
    "    # connect the two\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    opt = keras.optimizers.Adam(lr=0.002)\n",
    "    \n",
    "    if verbose:\n",
    "        ae_model.summary()\n",
    "    \n",
    "    ae_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['mse'])\n",
    "    \n",
    "    return name, ae_model, enc_model, dec_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train the model -- you should get a loss lower than 0.1 and MSE lower than 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train the model\n",
    "latent_width = 48\n",
    "name, ae_model, enc_model, dec_model = create_simple_ae(latent_width=latent_width, verbose=True)\n",
    "    \n",
    "max_epochs = 30\n",
    "batch_size = 256\n",
    "\n",
    "hist = ae_model.fit(train_x, train_x, epochs=max_epochs, batch_size=batch_size, validation_data=(val_x, val_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's reason about the architecture of this auto-encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1b] (5 points) Explain the choice of loss function: why is 'binary_crossentropy' a suitable loss function? (Hint: consider what the rest of the architecture looks like and what the data looks like.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1c] (5 points) Is the AE significantly overfitted? Why or why not? (Justify your answer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "# \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 2] (20 points) Using the AE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 2a] (10 points) Use plot_images() to plot the first 64 data points in val_x. Then reconstruct val_x through the AE. Finally, plot the first 64 data points of the reconstructed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 64 data points of val_x using plots.plot_images()\n",
    "###* put your code here (~1 line) *###\n",
    "\n",
    "\n",
    "# Run the first 64 data points in val_x through the auto-encoder to obtain reconstructed_val_x\n",
    "###* put your code here (~1 line) *###\n",
    "\n",
    "\n",
    "# Plot the reconstructed data (using plots.plot_images())\n",
    "###* put your code here (~1 line) *###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore the latent space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 2b] (10 points) Compute the average latent space representation of 0s and 8s in the validation data. Call these 'avg_zeros_latent' and 'avg_eights_latent' respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hint: first use the labels to identify which examples in the validation data are 0s and 8s\n",
    "###       Then compute the latent representation of these examples using the encoder\n",
    "###       Finally, take the mean of the latent representation for all 0s and then separately for all 8s.\n",
    "###* put your code here (~5-8 lines) *###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert avg_zeros_latent.shape == (latent_width,) or avg_zeros_latent.shape == (latent_width,1)\n",
    "assert avg_eights_latent.shape == (latent_width,) or avg_eights_latent.shape == (latent_width,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will look at the transition between 0 and 8 in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_exploration(source, target, num_steps):\n",
    "    diff = target - source\n",
    "    inc = diff / num_steps\n",
    "    \n",
    "    ret = np.zeros((num_steps, source.shape[0]))\n",
    "    for i in range(0, num_steps):\n",
    "        ret[i] = source + inc * i\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore linearly\n",
    "expl = linear_exploration(avg_zeros_latent, avg_eights_latent, 64)\n",
    "expl_as_images = dec_model.predict(expl)\n",
    "plots.plot_images(expl_as_images[0:64].reshape(-1, 28, 28), dim_x=28, dim_y=28, fig_size=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 3] (25 points) Extracting Features. Let's use the autoencoder for feature extraction. Then we will train a classifier on the basis of the extracted features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3a] (5 points) Extract feature representations for train_x, val_x, and test_x using the AE. Name the new feature matrices 'fext_train_x', 'fext_val_x' , and 'fext_test_x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your code here (~3 lines) *###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert fext_train_x.shape[1] == latent_width and fext_train_x.shape[1] == fext_val_x.shape[1] and fext_train_x.shape[1] == fext_test_x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3b] (20 points) Fill in the implementation of create_compile_classifier(). You can use an architecture of your choice (it can be simple), but the classifier must use the features (latent space representation) extracted by the AE. Your classifier should get 95%+ accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compile_classifier(latent_width=latent_width, num_outputs=10, verbose=True):\n",
    "    name = 'Model-ExtFeatures'\n",
    "    \n",
    "    ###* put your code here (~10 lines) *###\n",
    "    \n",
    "    \n",
    "    return name, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "_, classifier = create_compile_classifier(verbose=True)\n",
    "    \n",
    "max_epochs = 25\n",
    "batch_size = 64\n",
    "\n",
    "hist = classifier.fit(fext_train_x, train_y, epochs=max_epochs, batch_size=batch_size, validation_data=(fext_val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = classifier.evaluate(fext_test_x, test_y, verbose=0)\n",
    "\n",
    "print('[{}] Test loss: {:.5f}, test accuracy: {:.3f}%'.format(name, test_loss, 100*test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 4] (25 points) Sampling new data points. In this task, you will attempt to produce *new* images of digits using the auto-encoder and classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4a] (10 points) Briefly describe what you know about the range and distribution of the latent space of the AE (ae_model) trained in Task 1? (Hint: think about the architecture. What do you know about the latent space?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "# \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4b] (5 points) Given your answer to the previous question, provide a plausible distribution that you could easily sample from to obtain valid latent space points. For this you cannot use the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "# \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4c] (5 points) Complete the implementation of sample_new_digits() by sampling points from the distribution you mentioned in 4b. You should *not* use any data (train_x/y, val_x/y, test_x/y, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_new_digits(dec_model, count, latent_width=latent_width):\n",
    "    ### sample 'count' latent space points and store the resulting array in 'sampled_latent_space_points'\n",
    "    ###* put your code here (~1-2 lines) *###\n",
    "    \n",
    "    \n",
    "    \n",
    "    return dec_model.predict(sampled_latent_space_points) # decode the sampled points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's produce new images and see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 64 new images\n",
    "sample_images = sample_new_digits(dec_model, 64, latent_width=latent_width)\n",
    "\n",
    "# plot the produced images\n",
    "plots.plot_images(sample_images[0:64].reshape(-1, 28, 28), dim_x=28, dim_y=28, fig_size=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4d] (5 points) Do the new images look like digits? If not, explain why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "# \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CIS6930 Additional Task -- Task 5] (25 points): Variational AutoEncoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this task, you will use the provided VAE implementation in nets.py. The goal is to train the model and use it to generate new samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5a] (10 points) Fill in the implementation below to create the VAE and model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_width = 48\n",
    "\n",
    "### Create a VAE using nets.create_simple_vae() then train it for at least 25 epochs.\n",
    "### Make sure the latent width of the VAE is set to 48\n",
    "###* put your code here (~2-4 lines) *###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5b] (5 points) Similar to Task 2a, use plot_images() to plot the first 64 data points in the val_x. Then reconstruct val_x using the VAE and plot the first 64 data points of the reconstructed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 64 data points of val_x using plots.plot_images()\n",
    "###* put your code here (~1 line) *###\n",
    "\n",
    "\n",
    "# Run the first 64 data points in val_x through the VAE to obtain reconstructed_val_x\n",
    "###* put your code here (~1 line) *###\n",
    "\n",
    "\n",
    "# Plot the reconstructed data\n",
    "###* put your code here (~1 line) *###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5c] (5 points) What is the latent-space distribution for the VAE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "# \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5d] (5 points) Complete the implementation below by sampling points from the distribution you mentioned in 5c. You should *not* use any data (train_x/y, val_x/y, test_x/y, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You should sample 100 latent-space points (from the distribution you describe in 5c) and\n",
    "### then you should decode these points into images (call the resulting array 'sample_images').\n",
    "###* put your code here (~1-2 lines) *###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plots.plot_images(sample_images[0:64].reshape(-1, 28, 28), dim_x=28, dim_y=28, fig_size=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
