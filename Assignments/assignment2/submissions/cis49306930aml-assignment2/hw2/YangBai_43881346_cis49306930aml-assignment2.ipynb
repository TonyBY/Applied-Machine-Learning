{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: ML Engineering 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your name and UFL email address\n",
    "name = 'Yang Bai'\n",
    "email = 'baiyang94@ufl.edu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment 2 -- name: Yang Bai, email: baiyang94@ufl.edu\n",
      "\n",
      "### Python version: 3.8.3 (default, Jul  2 2020, 11:26:31) \n",
      "[Clang 10.0.0 ]\n",
      "### NumPy version: 1.19.5\n",
      "### Scikit-learn version: 0.23.1\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "if name == 'enter your name' or email == 'enter your email':\n",
    "    assert False, 'Enter your name & email first!'\n",
    "else:\n",
    "    print('Assignment 2 -- name: {}, email: {}\\n'.format(name, email))\n",
    "    \n",
    "    # Load packages we need\n",
    "    import sys\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import sklearn\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "    # Let's check our software versions\n",
    "    print('### Python version: ' + __import__('sys').version)\n",
    "    print('### NumPy version: ' + np.__version__)\n",
    "    print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "    print('------------')\n",
    "\n",
    "\n",
    "    # load our packages / code\n",
    "    sys.path.insert(1, '../common/')\n",
    "    import utils\n",
    "    import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters to control behavior of the pre-processing, ML, analysis, etc.\n",
    "seed = 42\n",
    "\n",
    "# deterministic seed for reproducibility\n",
    "##rng = np.random.default_rng(seed)  # best practice but not fully implemented in scikit-learn\n",
    "np.random.seed(seed)\n",
    "\n",
    "prop_vec = [16, 2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading and Pre-processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### In this case, we'll directly load the Adult dataset pre-processed in a similar way as for assignment 1\n",
    "### and we'll immediately split it into train, test, validation.\n",
    "\n",
    "train_x, train_y, test_x, test_y, val_x, val_y, features, labels = utils.load_preproc_adult(prop_vec=prop_vec, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (36178, 88), (36178,)\n",
      "Test: (4523, 88), (4523,)\n",
      "Validation: (4521, 88), (4521,)\n"
     ]
    }
   ],
   "source": [
    "# check that we have what we expect\n",
    "print('Training: {}, {}'.format(train_x.shape, train_y.shape))\n",
    "print('Test: {}, {}'.format(test_x.shape, test_y.shape))\n",
    "print('Validation: {}, {}'.format(val_x.shape, val_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['age', 'workclass_0', 'workclass_1', 'workclass_2', 'workclass_3', 'workclass_4', 'workclass_5', 'workclass_6', 'workclass_7', 'education-num', 'marital-status_0', 'marital-status_1', 'marital-status_2', 'marital-status_3', 'marital-status_4', 'marital-status_5', 'marital-status_6', 'occupation_0', 'occupation_1', 'occupation_2', 'occupation_3', 'occupation_4', 'occupation_5', 'occupation_6', 'occupation_7', 'occupation_8', 'occupation_9', 'occupation_10', 'occupation_11', 'occupation_12', 'occupation_13', 'relationship_0', 'relationship_1', 'relationship_2', 'relationship_3', 'relationship_4', 'relationship_5', 'race_0', 'race_1', 'race_2', 'race_3', 'race_4', 'sex_0', 'sex_1', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country_0', 'native-country_1', 'native-country_2', 'native-country_3', 'native-country_4', 'native-country_5', 'native-country_6', 'native-country_7', 'native-country_8', 'native-country_9', 'native-country_10', 'native-country_11', 'native-country_12', 'native-country_13', 'native-country_14', 'native-country_15', 'native-country_16', 'native-country_17', 'native-country_18', 'native-country_19', 'native-country_20', 'native-country_21', 'native-country_22', 'native-country_23', 'native-country_24', 'native-country_25', 'native-country_26', 'native-country_27', 'native-country_28', 'native-country_29', 'native-country_30', 'native-country_31', 'native-country_32', 'native-country_33', 'native-country_34', 'native-country_35', 'native-country_36', 'native-country_37', 'native-country_38', 'native-country_39', 'native-country_40']\n",
      "Labels: ['<=50K', '>50K']\n"
     ]
    }
   ],
   "source": [
    "# print features and labels\n",
    "print('Features: {}'.format(features))\n",
    "print('Labels: {}'.format(labels))\n",
    "\n",
    "# as you can see this the one-hot encoded version of the data with proper names for the columns/features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.94207283  1.          0.          0.          0.          0.\n",
      "  0.          0.          0.          1.12875281  0.          0.\n",
      "  1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.          0.          0.          0.\n",
      "  0.          1.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          1.\n",
      "  1.          0.         -0.1467332  -0.21878026  0.7547014   0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.        ]\n",
      "[1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at some rows of our training data just so we know what it looks like\n",
    "print(train_x[2,:])\n",
    "print(train_y[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 1] (30 points) Let's tune hyperparameters! We will use scikit-learn in two ways to optimize hyperparameters of SVM: (1) grid search, (2) randomized search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1a] (10 points) Use GridSearchCV from scikit-learn to do a grid search for SVM hyperparameters. Note that this way will use cross-validation to find the best hyperparameters values and that we purposefully disable some warnings to avoid verbose output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C':[0.1, 1, 5], 'penalty': ['l1', 'l2']}\n",
    "model = LinearSVC(max_iter=1000, dual=False)\n",
    "\n",
    "# We'll use this to avoid some annoying convergence warnings \n",
    "# Note: don't just do that without thinking in your own projects, warnings are there for a reason folks!\n",
    "## (In this case, it's okay because it's for illustration, but obviously if the model doesn't converge in \n",
    "## some cases we may not find the true best hyperparams)\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def do_grid_search(model, param_grid):\n",
    "    \n",
    "    # use the GridSearchCV class of scikit-learn to do a grid search on the provided grid (use 'model')\n",
    "    # set accuracy as scoring function and return the output of fit() on the training data\n",
    "    \n",
    "    ###* put your code here (~2 lines) *###\n",
    "    svm_cv = GridSearchCV(model, param_grid)\n",
    "    svm_cv.fit(train_x, train_y)\n",
    "\n",
    "#     print(\"Tuned Linear SVM Parameters: {}\".format(svm_cv.best_params_))  \n",
    "#     print(\"Best score is {}\".format(svm_cv.best_score_))\n",
    "    return svm_cv\n",
    "\n",
    "gs_res = do_grid_search(model, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1b] (3 points) How many combination of hyperparameters were tested?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer: the number of combination of hyperparameters is 6.\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1c] (2 points) What is the best combination of hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Linear SVM Parameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "Best score is 0.8485545091863879\n"
     ]
    }
   ],
   "source": [
    "# Show the best combination of parameters found through the search \n",
    "# Hint: look at the documentation of GridSearchCV\n",
    "###* put your code here (~2 lines) *###\n",
    "# store this combination in 'gs_best_hyperparams' and print it\n",
    "\n",
    "gs_best_hyperparams = gs_res.best_params_\n",
    "\n",
    "print(\"Tuned Linear SVM Parameters: {}\".format(gs_best_hyperparams))  \n",
    "print(\"Best score is {}\".format(gs_res.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1d] (10 points) Use RandomizedSearchCV to do a search! We'll use a halfnormal distribution from Scipy to find values for C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import halfnorm\n",
    "\n",
    "param_dist = dict(C=halfnorm(loc=0, scale=4.0), penalty=['l1', 'l2'])\n",
    "model = LinearSVC(max_iter=1000, dual=False)\n",
    "\n",
    "# We'll use this to avoid some annoying convergence warnings \n",
    "# Note: don't just do that in your own projects, warnings are there for a reason!\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def do_randomized_search(model, param_dist):\n",
    "    # use the RandomizedSearchCV class of scikit-learn to do a randomized search (use 'model')\n",
    "    # use accuracy as scoring function and return the result of fit() on the training data \n",
    "    # Also for reproducibility: set the random_state\n",
    "    \n",
    "    ###* put your code here (~2 lines) *###\n",
    "    svm_cv = RandomizedSearchCV(model, param_dist)\n",
    "    svm_cv.fit(train_x, train_y)\n",
    "    return svm_cv\n",
    "    \n",
    "rs_res = do_randomized_search(model, param_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1e] (1 points) What is the best combination of hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Linear SVM Parameters: {'C': 0.1386087369103972, 'penalty': 'l1'}\n",
      "Best score is 0.8485268581457299\n"
     ]
    }
   ],
   "source": [
    "# Show the best combination of parameters found through the randomized search \n",
    "###* put your code here (~1 line) *###\n",
    "rs_best_hyperparams = rs_res.best_params_\n",
    "\n",
    "print(\"Tuned Linear SVM Parameters: {}\".format(rs_best_hyperparams))  \n",
    "print(\"Best score is {}\".format(rs_res.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1f] (4 points) What are the pros and cons of a randomized search? Explain your answer. (A few sentences is okay.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do you think are the pros and cons of a randomized search?\n",
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer: \n",
    "# Pros: Faster, especailly when the number of hyperparemeter is huge. \n",
    "# Because it doesn't test the full range of possibilities, and hence it can reduce unnecessary computation.\n",
    "# Cons: It cannot guarantee to finded the optimal hyperparameter combination.\n",
    "# Because it won't go through every combination.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 2] (10 points) Let's train the model and evaluate it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(w/ best grid search hyperparams {'C': 0.1, 'penalty': 'l1'}): \n",
      "\t--- Training accuracy: 84.99%, Validation accuracy: 84.67%\n"
     ]
    }
   ],
   "source": [
    "# complete the function to calculate accuracy (value in [0,1] range)\n",
    "def model_accuracy(model, x, true_y):\n",
    "    ###* put your code here (~2 lines) *###\n",
    "    pred = model.predict(x)\n",
    "    return np.sum(pred == true_y) / true_y.shape[0]\n",
    "\n",
    "def evaluate_model(name, model, train_x, train_y, val_x, val_y):\n",
    "    train_acc = model_accuracy(model, train_x, train_y)\n",
    "    val_acc = model_accuracy(model, val_x, val_y)\n",
    "    print('{}: \\n\\t--- Training accuracy: {:.2f}%, Validation accuracy: {:.2f}%'.format(name, train_acc*100, val_acc*100))\n",
    "    return\n",
    "\n",
    "###* put your code here (~1 line) *### \n",
    "### Train a LinearSVC using the best hyperparameters found during the grid search in Task 1\n",
    "### In addition you should also use: max_iter=10000, dual=False\n",
    "### Use the training data (train_x, train_y)\n",
    "### Hint: there is a way to pass the best hyperparameters object from Task 1b directly to the model object (i.e., without passing it one hyperparameter at a time)\n",
    "\n",
    "svm = LinearSVC(max_iter=10000, dual=False).set_params(**gs_best_hyperparams).fit(train_x, train_y)\n",
    "\n",
    "evaluate_model('LinearSVC(w/ best grid search hyperparams {})'.format(gs_best_hyperparams), \n",
    "               svm, train_x, train_y, val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 3] (30 points) Manual Hyperparameter Optimization (i.e., without using scikit-learn's to do the search for us)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3a] (10 points) Complete the code below to do a grid search manually. In this case you cannot use GridSearchCV, you must train and evaluate the model on each combination of hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, hyperparams: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 99.10%, val accuracy: 79.25%\n",
      "Iter 1, hyperparams: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.10%, val accuracy: 79.25%\n",
      "Iter 2, hyperparams: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 89.62%, val accuracy: 81.53%\n",
      "Iter 3, hyperparams: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 80.71%\n",
      "Iter 4, hyperparams: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 87.56%, val accuracy: 81.80%\n",
      "Iter 5, hyperparams: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 81.09%\n",
      "Iter 6, hyperparams: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 86.96%, val accuracy: 82.06%\n",
      "Iter 7, hyperparams: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 81.40%\n",
      "Iter 8, hyperparams: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 85.88%, val accuracy: 82.99%\n",
      "Iter 9, hyperparams: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 82.00%\n",
      "Iter 10, hyperparams: {'metric': 'euclidean', 'n_neighbors': 51, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 84.12%, val accuracy: 82.88%\n",
      "Iter 11, hyperparams: {'metric': 'euclidean', 'n_neighbors': 51, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 82.66%\n",
      "Iter 12, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 99.10%, val accuracy: 77.93%\n",
      "Iter 13, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 1, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.10%, val accuracy: 77.93%\n",
      "Iter 14, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 89.04%, val accuracy: 79.58%\n",
      "Iter 15, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 3, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 78.77%\n",
      "Iter 16, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 86.62%, val accuracy: 79.96%\n",
      "Iter 17, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 5, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 79.32%\n",
      "Iter 18, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 85.58%, val accuracy: 81.27%\n",
      "Iter 19, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 7, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 80.69%\n",
      "Iter 20, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 84.36%, val accuracy: 81.40%\n",
      "Iter 21, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 11, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 80.82%\n",
      "Iter 22, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 51, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 82.78%, val accuracy: 81.53%\n",
      "Iter 23, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 51, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 81.44%\n"
     ]
    }
   ],
   "source": [
    "## we are allowed to use the following from scikit-learn\n",
    "from sklearn.model_selection import ParameterGrid \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "hyperparams_vals = {'weights': ['uniform', 'distance'],\n",
    "                    'metric': ['euclidean', 'chebyshev'],\n",
    "                    'n_neighbors': [1, 3, 5, 7, 11, 51]}\n",
    "\n",
    "grid = ParameterGrid(hyperparams_vals)\n",
    "\n",
    "trsub_size = 5000\n",
    "trsub_x = train_x[:trsub_size,:]\n",
    "trsub_y = train_y[:trsub_size]\n",
    "\n",
    "## iterate over the entire grid. In each case, train a KNN classifier with the given hyperparameters (on the training subset 'trsub')\n",
    "# and measure accuracy on both the training subset data and the validation data!\n",
    "# note: we use a subset of the training data to speed up the process a bit\n",
    "for i, hyperparams in enumerate(list(grid)):\n",
    "    \n",
    "    ###* put your code here  (~ 5 lines) *###\n",
    "    ### In each iteration of the loop you should train a KNeighborsClassifier using 'hyperparams' as hyperparameters\n",
    "    ### You should train the model on 'trsub_x' and 'trsub_y'!\n",
    "    ### Once your model is trained, compute the accuracy on trsub (training accuracy) and on val (validation accuracy) \n",
    "    ### store the results in 'train_acc' and 'val_acc' respectively\n",
    "    knn = KNeighborsClassifier().set_params(**hyperparams).fit(trsub_x, trsub_y)\n",
    "    train_acc = model_accuracy(knn, trsub_x, trsub_y)\n",
    "    val_acc = model_accuracy(knn, val_x, val_y)\n",
    "    \n",
    "    ## This will print information about the grid search as it progresses\n",
    "    print('Iter {}, hyperparams: {}\\n \\t-> train accuracy: {:.2f}%, val accuracy: {:.2f}%'.\n",
    "              format(i, hyperparams, 100*train_acc, 100*val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3b] (5 points) Answer the following questions. (A few sentences is fine.)\n",
    "### What combination of hyperparameters would you use and why? Is the training accuracy useful when doing hyperparameter tuning? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What combination of hyperparameters would you use and why?\n",
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer: \n",
    "# The conbination of hyperparameters that I would use is: \n",
    "# {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}\n",
    "# Because under this conbination of hyperparameter, the KNN model gets the heightest validation accuracy \n",
    "# according to the above results.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the training accuracy useful when doing hyperparameter tuning? Why or why not?\n",
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer: \n",
    "# Training accuracy is not super useful for doing hyperparameter tuning. \n",
    "# Because we want to find the combination of hyperparameter that can give us the best generalization, i.e. \n",
    "# the heighest accuracy over the new data (the validation data here).\n",
    "# But training accuracy along with validatoin accuracy can help us check which combination of hyperparameter \n",
    "# will cause overfitting, and hence gives us a better insight of these hyperparameters.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3d] (10 points) Answer the following questions. (A few sentences is fine.)\n",
    "### Observe what happens when weights changes from 'uniform' to 'distance'? Provide a plausible explanation for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you observe in terms of the training and validation accuracies when the weights change from 'uniform' to \n",
    "# 'distance'?\n",
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer: \n",
    "# I find that when the weights change from 'uniform' to 'distance', in most cases,\n",
    "# the accuracy of training set increased a lot, \n",
    "# while the accuracy of the validation set drops a little bit.\n",
    "# \n",
    "\n",
    "\n",
    "## provide a plausible explanation for this phenomenon.\n",
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer: \n",
    "# When using the 'distance' weight, the model will give a weight over the vote of the k nearest neighbors based on\n",
    "# their distance to the example. The closer the neighbor is the higher the weight it will get. This obviously\n",
    "# will increase the accuracy of the training set because their always a correct neighbor in the model has \n",
    "# 0 distance with the input example, because the correct neighbor would be the input example itself. But this case\n",
    "# does not hold in the validation set. Hence, the 'distance' weight makes the model overfit to the training set.\n",
    "#\n",
    "\n",
    "## If you were to train a KNN model would you set weights to 'uniform' or 'distance'? Why?\n",
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer: \n",
    "# I would set weights to 'uniform' because it gives better generalization, i.e. the heighest accuracy \n",
    "# over new data (validation data here).\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3e] (5 points) Which hyperparameters (if any) have a significant impact on overfitting and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### According to the grid search you just performed, which hyperparameters seem to have significant impact on overfitting and why?\n",
    "## Explain your reasoning and justify your answer!\n",
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer: \n",
    "# According to the grid search, looks like the hyperparameter 'weights' has significant impact on \n",
    "# overfitting. Because, in most cases, when changing 'weights' from 'uniform' to 'distance' while \n",
    "# keeping other hyperparameters the same, the training accracy increased a lot to over 99% but the validation\n",
    "# accuracy drops a little bit which indicates the generalization goes down. It is an obvious phenomenon of \n",
    "# overfitting.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 4] (30 points) Exploring Bias & Variance, Underfitting & Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this task, you *must* only use models (kNN or SVM) and hyperparameters that we have seen/used somewhere in this assignment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4a] (5 points) What is the irreducible error for this prediction task (income >=50k or <50k on Adult data)? Explain your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer: \n",
    "# I think the irreducible error for this prediction task is about 15%. Because the heightest validation \n",
    "# accuracy we have ever had in the above experiments is 84.86% with SVM when using the best combination of \n",
    "# hyperparameter that we got using grid search.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the rest of Task 4, we will assume that irreducible error (in the scale 1 - accuracy) is about 15%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4b] (5 points) Train a high bias, low variance model. Show *and* explain why the model has high bias and low variance! (Use evaluate_model() to calculate and display training accuracy and validation accuracy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(w/ high bias, low variance.): \n",
      "\t--- Training accuracy: 75.39%, Validation accuracy: 74.19%\n"
     ]
    }
   ],
   "source": [
    "###* Put your code here (~2 lines) *###\n",
    "svm = LinearSVC(max_iter=5, dual=False, C = 0.00001, penalty='l1').fit(train_x, train_y)\n",
    "evaluate_model('LinearSVC(w/ high bias, low variance.)', \n",
    "               svm, train_x, train_y, val_x, val_y)\n",
    "###* put your answer as comment here *###\n",
    "# \n",
    "# Answer: \n",
    "# This model has a relatively low training accuracy(75.39%) and a very close validation \n",
    "# accuracy(74.19%). This indicats that this model is underfitting but it generalizes well. \n",
    "# Hence, we can tell this is a high bias low variance model.\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4c] (5 points) Train a low bias, high variance model. Show *and* explain why the model has low bias and high variance! (Use evaluate_model() to calculate and display training accuracy and validation accuracy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(w/ low bias, high variance.): \n",
      "\t--- Training accuracy: 99.16%, Validation accuracy: 78.77%\n"
     ]
    }
   ],
   "source": [
    "###* Put your code here (~2 lines) *###\n",
    "knn = KNeighborsClassifier(metric = 'chebyshev', n_neighbors = 3, weights = 'distance').fit(trsub_x, trsub_y)\n",
    "evaluate_model('KNeighborsClassifier(w/ low bias, high variance.)', \n",
    "               knn, trsub_x, trsub_y, val_x, val_y)\n",
    "\n",
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer: This model has a very high training accuracy(99.16%) and a much lower validation accuracy(78.77). This\n",
    "# indicates that this model is overfitted. Hence, we can tell this is a low bias, high variance model.\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4d] (5 points) Train a low bias, low variance model. Show *and* explain why the model has low bias and low variance! (Use evaluate_model() to calculate and display training accuracy and validation accuracy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(w/ low bias, low variance.): \n",
      "\t--- Training accuracy: 85.06%, Validation accuracy: 84.67%\n"
     ]
    }
   ],
   "source": [
    "###* Put your code here (~2 lines) *###\n",
    "svm = LinearSVC(max_iter=10000, dual=False, C = 0.1).fit(train_x, train_y)\n",
    "evaluate_model('LinearSVC(w/ low bias, low variance.)', \n",
    "               svm, train_x, train_y, val_x, val_y)\n",
    "\n",
    "\n",
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer: Given that the irreducibel error is 15%. A 85.06% training accuracy and a 84.67% validation accuracy are\n",
    "# both very high and close to each other, which means that this model has a low bias and a low varicance.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4e] (5 points) Can you train a high bias, high variance model. If so how? If not why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* Put your code here (if applicable) *###\n",
    "\n",
    "\n",
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer: I don't think that I can train such a model that has high bias and high variance at the same time.\n",
    "# Because high bias means underfitting, and it means the model cannot even properly extract/utilize the features\n",
    "# in the training set to make prediction, so I don't think it is realistic to create a high biased model that also \n",
    "# has high variance.\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4f] (5 points) Train a badly *underfitted* model. The accuracy should be below 55%! (Use evaluate_model() to calculate and display training accuracy and validation accuracy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(w/ badly underfitting): \n",
      "\t--- Training accuracy: 55.00%, Validation accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "###* Put your code here (~2 lines) *###\n",
    "\n",
    "svm = LinearSVC(max_iter=10, dual=False, C = 0.01, penalty='l1').fit(train_x[:20], train_y[:20])\n",
    "evaluate_model('LinearSVC(w/ badly underfitting)', svm, train_x[:20], train_y[:20], val_x[:4], val_y[:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CIS6930 Additional Task -- Task 5] (25 points): Variance, Overfitting, Agreement Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose we have two models and want to compare them and instead of comparing them in terms of how good the models are, we care about whether the models have learned a similar relationship between features and label? One way we can measure this is using agreement rate: we use both models to make predictions on a separate dataset and then measure what proportion of those predictions are identical.\n",
    "\n",
    "### Variance is the tendency to learn non-existing/wrong relationships between features and labels based on the idiosyncracies of the training data. So intuitively, if two models are trained on disjoint but randomly selected subsets of the training data, then if the variance is high the agreement rate between the two models should be low. So, we can try to measure variance by measuring agreement rate. But does this work? This is what you will explore experimentally in this task. (Note that overfitting and variance are related but are not the same thing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5a] (5 points) Implement an overfitting measure and the agreement rate metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We'll define two metrics, one for overfitting and the other for agreement rate\n",
    "\n",
    "## for this assignment we define overfitting measure as the max between 0 and \n",
    "## the difference between training accuracy and validation accuracy\n",
    "def overfitting_measure(train_acc, val_acc):\n",
    "    ###* put your code here (~1 line) *###\n",
    "    ### your code should return the maxmimum between: 0 and training accuracy - validation accuracy\n",
    "    return max(0, train_acc - val_acc)\n",
    "\n",
    "\n",
    "\n",
    "## the agreement rate is the proportion of identical prediction of both models on a separate dataset\n",
    "## note: we don't care if the predictions are correct, we only care how often they are the same!\n",
    "def agreement_rate(m1_preds, m2_preds):\n",
    "    assert m1_preds.shape == m2_preds.shape\n",
    "    \n",
    "    ###* put your code here (~1 line) *###\n",
    "    ### your code should return the proportion of identical predictions in m1_preds and m2_preds\n",
    "    ### note: the agreement rate is a value in [0, 1] so make sure your code returns values in the same range!\n",
    "    \n",
    "    return (1 - np.count_nonzero((m1_preds - m2_preds)) / len(m1_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def eval_accuracy(model, train_x, train_y, val_x, val_y):\n",
    "    train_acc = model_accuracy(model, train_x, train_y)\n",
    "    val_acc = model_accuracy(model, val_x, val_y)\n",
    "    \n",
    "    return train_acc, val_acc\n",
    "\n",
    "def measure_overfitting_agreement(model, train_x, train_y, trsz, val_x, val_y):\n",
    "    m1 = clone(model)\n",
    "    m2 = clone(model)\n",
    "    \n",
    "    n = train_x.shape[0]\n",
    "    assert n/2 >= trsz and trsz > 0\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    pi = rng.permutation(n)\n",
    "    pi1 = pi[0:trsz]\n",
    "    pi2 = pi[trsz:2*trsz]\n",
    "    \n",
    "    m1.fit(train_x[pi1], train_y[pi1])\n",
    "    m2.fit(train_x[pi2], train_y[pi2])\n",
    "    \n",
    "    train_acc, val_acc = eval_accuracy(m1, train_x[pi1], train_y[pi1], val_x, val_y)\n",
    "    m1_overfit =  np.maximum(0, train_acc - val_acc)\n",
    "    \n",
    "    train_acc, val_acc = eval_accuracy(m2, train_x[pi2], train_y[pi2], val_x, val_y)\n",
    "    m2_overfit =  np.maximum(0, train_acc - val_acc)\n",
    "    \n",
    "    m1_val_pred = m1.predict(val_x)\n",
    "    m2_val_pred = m2.predict(val_x)\n",
    "    \n",
    "    agr = agreement_rate(m1_val_pred, m2_val_pred)\n",
    "    \n",
    "    # for this task, we'll define our our overfitting measure as \n",
    "    # the average of the overfitting measure of the two models\n",
    "    overfit = (m1_overfit + m2_overfit)/2.0 \n",
    "    \n",
    "    return overfit, agr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5b] (10 points) Train SVM models on random subsets of the data with different C (regularization constant) and two different size for the training data. In each case, use measure_overfitting_agreement() defined above to train the models and compute overfitting and agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(-2,3,200)\n",
    "training_sizes = [100, 200]\n",
    "\n",
    "###* put your code here *###\n",
    "### your code should use 'SVC(C=<value from Cs>, kernel='linear')' as model instances\n",
    "### You should invoke measure_overfitting_agreement() to get the agreement rate and overfitting measure \n",
    "### (do this for all values in 'Cs' and both training sizes)\n",
    "### and store the results in some array(s) of your choice so that you can plot this for Task 5c\n",
    "\n",
    "overfit100_array = np.array([])\n",
    "agr100_array = np.array([])\n",
    "overfit200_array = np.array([])\n",
    "agr200_array = np.array([])\n",
    "for c in Cs:\n",
    "#     print('-------------------')\n",
    "#     print(\"C = \", c)\n",
    "    for trsz in training_sizes:\n",
    "#         print(\"trsz: \", trsz)\n",
    "        svm = SVC(C = c, kernel='linear')\n",
    "        overfit, agr = measure_overfitting_agreement(svm, train_x, train_y, trsz, val_x, val_y)\n",
    "        \n",
    "#         print(\"overfit: \", overfit)\n",
    "#         print(\"\\n################\\n\")\n",
    "#         print(\"agr: \", agr)\n",
    "#         break\n",
    "        \n",
    "        if trsz == 100:\n",
    "            overfit100_array = np.append(overfit100_array, overfit)\n",
    "            agr100_array = np.append(agr100_array, agr)\n",
    "        else:\n",
    "            overfit200_array = np.append(overfit200_array, overfit)\n",
    "            agr200_array = np.append(agr200_array, agr)\n",
    "\n",
    "# print(\"overfit100_array: \", overfit100_array)\n",
    "# print(\"\\n################\\n\")\n",
    "# print(\"agr100_array: \", agr100_array)\n",
    "\n",
    "# print(\"\\n################\\n\")\n",
    "\n",
    "# print(\"overfit200_array: \", overfit200_array)\n",
    "# print(\"\\n################\\n\")\n",
    "# print(\"agr200_array: \", agr200_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5c] (5 points) Plot overfitting vs disagreement rate as a scatter plot for both training sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Use matplotlib and supplement the provided code so it produces a single scatter plot of the two training set sizes\n",
    "### with overfitting on the x-axis and *disagreement* (i.e., 1 - agreement rate) on the y-axis.\n",
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "\n",
    "###* put your code here (~2 lines) *###\n",
    "### Invoke plt.scatter() first for Training Set Size: 100; use blue circle marker.\n",
    "### Invoke plt.scatter() again this time for Training Set Size: 200; use red square marker.\n",
    "plt.scatter(overfit100_array, 1 - agr100_array, marker='o', c= 'blue', label='Training Set Size: 100')\n",
    "plt.scatter(overfit200_array, 1 - agr200_array, marker='s', c= 'red', label='Training Set Size: 200')\n",
    "\n",
    "\n",
    "## sets the axis labels, limits, etc.\n",
    "plt.xlabel('Overfitting Measure')\n",
    "plt.ylabel('Disagreement Rate (1 - Agreement Rate)')\n",
    "plt.xlim([-0.02, 0.3])\n",
    "plt.ylim([-0.02, 0.45])\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5d] (5 points) What do you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you conclude? Is agreement rate a possible way to measure overfitting? Can it be used to measure variance?\n",
    "# Describe your general observation of the correlation between these measures.\n",
    "# Hint: there is no single 'right' answer here, but there are many wrong answers!\n",
    "###* put your answer as comment here *###\n",
    "#\n",
    "# Answer:\n",
    "# From above figure, I can see that the Overfitting Measure and the Disagreement Rate are positively correlated, \n",
    "# which means that the higher the Overfittingthe lower the Agreement Rate. It means that the agreement rate\n",
    "# is a possible way to measure overfitting.\n",
    "# \n",
    "# However, I don't think agreement rate can be used to measure variance, because a low agreement rate could be \n",
    "# caused by many reasons like high bias or high variance, hence it does not have a certain relation with variance.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
