{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your name and UFL email address\n",
    "name = 'Yang Bai'\n",
    "email = 'baiyang94@ufl.edu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment 3 -- name: Yang Bai, email: baiyang94@ufl.edu\n",
      "\n",
      "### Python version: 3.8.3 (default, Jul  2 2020, 11:26:31) \n",
      "[Clang 10.0.0 ]\n",
      "### NumPy version: 1.19.5\n",
      "### Scikit-learn version: 0.23.1\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "if name == 'enter your name' or email == 'enter your email':\n",
    "    assert False, 'Enter your name & email first!'\n",
    "else:\n",
    "    print('Assignment 3 -- name: {}, email: {}\\n'.format(name, email))\n",
    "    \n",
    "    # Load packages we need\n",
    "    import sys\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import sklearn\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "    # Let's check our software versions\n",
    "    print('### Python version: ' + __import__('sys').version)\n",
    "    print('### NumPy version: ' + np.__version__)\n",
    "    print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "    print('------------')\n",
    "\n",
    "\n",
    "    # load our packages / code\n",
    "    sys.path.insert(1, '../common/')\n",
    "    import utils\n",
    "    import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters to control behavior of the pre-processing, ML, analysis, etc.\n",
    "seed = 42\n",
    "\n",
    "# deterministic seed for reproducibility\n",
    "##rng = np.random.default_rng(seed)  # best practice but not fully implemented in scikit-learn\n",
    "np.random.seed(seed)\n",
    "\n",
    "prop_vec = [14, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading and Pre-processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this assignment we'll load the Bike Sharing dataset (hourly)\n",
    "### This dataset contains features of users bike sharing/rental on an hourly basis.\n",
    "### The task is to predict how many users are sharing/renting a bike."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   season      16320 non-null  float64\n",
      " 1   year        16231 non-null  float64\n",
      " 2   month       16304 non-null  float64\n",
      " 3   hour        16254 non-null  float64\n",
      " 4   holiday     16277 non-null  float64\n",
      " 5   weekday     16282 non-null  float64\n",
      " 6   workingday  16297 non-null  float64\n",
      " 7   weathersit  16324 non-null  float64\n",
      " 8   temp        16242 non-null  float64\n",
      " 9   atemp       16271 non-null  float64\n",
      " 10  hum         16252 non-null  float64\n",
      " 11  windspeed   16281 non-null  float64\n",
      " 12  registered  16244 non-null  float64\n",
      " 13  nsqrtc      16263 non-null  float64\n",
      " 14  count       17379 non-null  int64  \n",
      "dtypes: float64(14), int64(1)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "### Note: this dataset has missing values (artificially introduced), which you'll need to fill in before you can train a model\n",
    "df = pd.read_csv('../data/bikesharehour.csv.gz', compression='gzip', header=0, na_values='?')\n",
    "\n",
    "# Check that we loaded the data as expected\n",
    "df_expected_shape = (17379, 15)\n",
    "\n",
    "assert df.shape == df_expected_shape, 'Unexpected shape of df!'\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>registered</th>\n",
       "      <th>nsqrtc</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  year  month  hour  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0     1.0   0.0    NaN   0.0      0.0      6.0         0.0         1.0   NaN   \n",
       "1     1.0   0.0    NaN   1.0      0.0      6.0         0.0         1.0   NaN   \n",
       "2     1.0   0.0    1.0   2.0      0.0      6.0         0.0         1.0   0.0   \n",
       "3     1.0   0.0    1.0   3.0      0.0      6.0         0.0         1.0   0.0   \n",
       "4     1.0   0.0    1.0   4.0      0.0      6.0         0.0         1.0   0.0   \n",
       "\n",
       "   atemp  hum  windspeed  registered  nsqrtc  count  \n",
       "0    0.0  0.0        0.0        13.0    -5.0     16  \n",
       "1    0.0  0.0        0.0        32.0    -8.0     40  \n",
       "2    0.0  0.0        0.0        27.0    -7.0     32  \n",
       "3    0.0  0.0        0.0        10.0    -5.0     13  \n",
       "4    0.0  0.0        0.0         1.0     0.0      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what does the data look like?\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are some NaNs which we'll have to impute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all the data as a numpy matrix\n",
    "all_xy = df.to_numpy()\n",
    "\n",
    "col_names = [c for c in df.columns]\n",
    "features = col_names[:-1]\n",
    "target = col_names[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['season', 'year', 'month', 'hour', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'registered', 'nsqrtc'] --- target: count\n"
     ]
    }
   ],
   "source": [
    "print('features: {} --- target: {}'.format(features, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1059, 1148, 1075, 1125, 1102, 1097, 1082, 1055, 1137, 1108, 1127,\n",
       "       1098, 1135, 1116,    0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many NaNs in each column?\n",
    "np.sum(np.isnan(all_xy), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe: no NaNs in the target/value column\n",
    "### About 1000+ NaNs in each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into x and y\n",
    "all_x_nan = all_xy[:,:-1]\n",
    "all_y = all_xy[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's impute the missing values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "###* put your code here (~2-3 lines) *###\n",
    "mf_imputer = SimpleImputer(missing_values=np.nan, strategy='median', copy=True)\n",
    "\n",
    "all_x_mf = mf_imputer.fit_transform(all_x_nan)\n",
    "all_x = all_x_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the shape is correct\n",
    "assert all_x.shape == (17379, 14)\n",
    "\n",
    "# check that there are no more NaNs\n",
    "assert np.sum(np.sum(np.isnan(all_x), axis=0)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we start, we'll min-max normalize the features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(copy=True)\n",
    "scaler.fit(all_x) \n",
    "\n",
    "scaled_all_x = scaler.transform(all_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12166, 14), (12166,), (2607, 14), (2607,), (2606, 14), (2606,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into train, test, val\n",
    "train_x, train_y, test_x, test_y, val_x, val_y = utils.train_test_val_split(scaled_all_x, all_y, prop_vec, shuffle=True, seed=seed)\n",
    "\n",
    "# sanity check shapes\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape, val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 1] (35 points) Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train a linear regression model that we can use as a point of comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lrmodel = LinearRegression().fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's implement batch gradient descent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(X, y, gradient_fn, lr_schedule_fn, num_iter=1000, stop_fn = None, verbose=False):\n",
    "    (n, m) = X.shape\n",
    "    theta = np.random.uniform(low=-1.0, high=1.0, size=(X.shape[1],1)) # initialize uniformly at random in [-1, 1]\n",
    "    \n",
    "    for i in range(0, num_iter):\n",
    "        eta = lr_schedule_fn(i) # learning rate\n",
    "        \n",
    "        gradient = gradient_fn(X, y, theta) # calculate gradient vector\n",
    "        assert gradient.shape == theta.shape\n",
    "        \n",
    "        prev_theta = theta \n",
    "        \n",
    "        # update theta (actual gradient descent step)\n",
    "        theta = theta - eta * gradient\n",
    "        \n",
    "        # compute diff \n",
    "        diff = theta - prev_theta\n",
    "        l2ndiff = np.linalg.norm(diff)\n",
    "        \n",
    "        if verbose and i % (num_iter/20) == 0:\n",
    "            print('Iter {}, learning rate: {:.6f}, diff in theta (L2-norm): {:.6f}.'.format(i, eta, l2ndiff))\n",
    "            \n",
    "        if stop_fn is not None and stop_fn(diff):\n",
    "            if verbose:\n",
    "                print('Stop condition reached (iter {}).'.format(i))\n",
    "            break\n",
    "    \n",
    "    return theta.reshape(-1,), i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1a] (5 points) Define a constant learning rate schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a constant schedule, it should always return the learning rate eta (regardless of iteration)\n",
    "def constant_lr_schedule(eta, iteration):\n",
    "    ###* put your code here (~1 line) *###\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1b] (20 points) Implement gradient_mse() which calculates the gradient vector of MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For this you'll want to go back to the course slides (e.g., lecture 10 slide 7) or spend some time figuring out the gradient of MSE \n",
    "### (the loss) with respect to the parameters (i.e., theta which includes the weights vector w and bias b)\n",
    "### Note: asserts are there to help you ensure that things have the right shape. \n",
    "### If you get shape errors when running your code, you should think about what shape each component of the gradient should have.\n",
    "def gradient_mse(X, y, theta):\n",
    "    (n, m) = X.shape\n",
    "    \n",
    "    y = y.reshape(-1,1)\n",
    "    assert y.shape == (n,1)\n",
    "    assert theta.shape == (m,1)\n",
    "    \n",
    "    ### Recall that the gradient of MSE is: - 2/n X^T (θ X - y)   (note: θ = theta)\n",
    "    ###* put your code here (~1-4 lines) *###\n",
    "    \n",
    "    return 2.0/n * np.dot(X.T, (np.dot(X, theta) - y))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's train the model (theta) using batch_gradient_descent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, learning rate: 0.050000, diff in theta (L2-norm): 35.750811.\n",
      "Iter 2500, learning rate: 0.050000, diff in theta (L2-norm): 0.015696.\n",
      "Iter 5000, learning rate: 0.050000, diff in theta (L2-norm): 0.000253.\n",
      "Iter 7500, learning rate: 0.050000, diff in theta (L2-norm): 0.000074.\n",
      "Iter 10000, learning rate: 0.050000, diff in theta (L2-norm): 0.000072.\n",
      "Iter 12500, learning rate: 0.050000, diff in theta (L2-norm): 0.000071.\n",
      "Iter 15000, learning rate: 0.050000, diff in theta (L2-norm): 0.000070.\n",
      "Iter 17500, learning rate: 0.050000, diff in theta (L2-norm): 0.000068.\n",
      "Iter 20000, learning rate: 0.050000, diff in theta (L2-norm): 0.000067.\n",
      "Iter 22500, learning rate: 0.050000, diff in theta (L2-norm): 0.000065.\n",
      "Iter 25000, learning rate: 0.050000, diff in theta (L2-norm): 0.000064.\n",
      "Iter 27500, learning rate: 0.050000, diff in theta (L2-norm): 0.000063.\n",
      "Iter 30000, learning rate: 0.050000, diff in theta (L2-norm): 0.000061.\n",
      "Iter 32500, learning rate: 0.050000, diff in theta (L2-norm): 0.000060.\n",
      "Iter 35000, learning rate: 0.050000, diff in theta (L2-norm): 0.000059.\n",
      "Iter 37500, learning rate: 0.050000, diff in theta (L2-norm): 0.000058.\n",
      "Iter 40000, learning rate: 0.050000, diff in theta (L2-norm): 0.000057.\n",
      "Iter 42500, learning rate: 0.050000, diff in theta (L2-norm): 0.000055.\n",
      "Iter 45000, learning rate: 0.050000, diff in theta (L2-norm): 0.000054.\n",
      "Iter 47500, learning rate: 0.050000, diff in theta (L2-norm): 0.000053.\n"
     ]
    }
   ],
   "source": [
    "# add a constant feature of 1 to each row to account for the bias term\n",
    "X_with_b = np.c_[np.ones((train_x.shape[0],1)), train_x]\n",
    "\n",
    "grad_fn = gradient_mse\n",
    "\n",
    "# use a lambda to define the constant schedule with the learning rate baked in\n",
    "learning_rate = 0.05\n",
    "lr_sched_fn = lambda i: constant_lr_schedule(learning_rate, i)\n",
    "\n",
    "# actually run the gradient descent and store the result in theta\n",
    "theta, _ = batch_gradient_descent(X_with_b, train_y, grad_fn, lr_sched_fn, num_iter=50000, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1c] (5 points) Extract the parameters (w, b) from theta, then compare them to the parameters of the linear regression model (lrmodel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model -- w: [ 19.048  9.152 -10.044  37.807 -9.086  6.724 -34.405 -26.372  9.858\n",
      " -2.772 -9.309  20.558  1000.480 -12.950], b: 17.438\n",
      "Batch Gradient Descent model -- w: [ 19.049  9.153 -10.044  37.809 -9.087  6.726 -34.407 -26.373  3.576\n",
      " -1.847 -9.309  20.557  1000.480 -12.956], b: 17.441\n"
     ]
    }
   ],
   "source": [
    "# Print the weights and bias for both models\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "print('Linear Regression model -- w: {}, b: {:.3f}'.format(lrmodel.coef_, lrmodel.intercept_))\n",
    "\n",
    "### extract (w,b) from theta and print them\n",
    "###* put your code here (~2 lines) *###\n",
    "b = theta[0]\n",
    "w = theta[1:]\n",
    "\n",
    "print('Batch Gradient Descent model -- w: {}, b: {:.3f}'.format(w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1d] (5 points) What do you notice? Is it expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "# Answer:\n",
    "# I notice that the parameters between the linear regression model and the batch gradient decent model are very \n",
    "# similar.\n",
    "# It is expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 2] (35 points) Implementing Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 2a] (10 points) Fill in the implementation of SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, gradient_fn, lr_schedule_fn, num_epochs=1000, stop_fn=None, verbose=False):\n",
    "    (n, m) = X.shape\n",
    "    theta = np.random.uniform(low=-1.0, high=1.0, size=(X.shape[1],1)) # initialize uniformly at random in [-1, 1]\n",
    "    \n",
    "    for i in range(0, num_epochs):\n",
    "        prev_theta = theta\n",
    "\n",
    "        # in each epoch go over the entire data\n",
    "        rng = np.random.default_rng(seed=seed)\n",
    "        for j in range(0, n):\n",
    "            t = i*n+j\n",
    "            eta = lr_schedule_fn(t)\n",
    "            \n",
    "            ### Pick a *single* example out of the training data (X, y) uniformly at random, that is: \n",
    "            ### the feature vector and corresponding target/label\n",
    "            ### Call the feature vector 'xc' and the target/label 'yc'\n",
    "            ###* put your code here (~2-3 lines) *###\n",
    "            \n",
    "            row_idx = rng.integers(0, n)\n",
    "            xc = X[row_idx, :]\n",
    "            yc = y[row_idx]\n",
    "            \n",
    "            assert xc.shape == (m,) and yc.shape == ()\n",
    "            \n",
    "            # calculate gradients\n",
    "            gradient = gradient_fn(xc.reshape(1,-1), yc.reshape(-1,1), theta) \n",
    "            assert gradient.shape == theta.shape\n",
    "            \n",
    "            # update theta (actual gradient descent step)\n",
    "            theta = theta - eta * gradient\n",
    "\n",
    "        # compute diff \n",
    "        diff = theta - prev_theta\n",
    "        l2ndiff = np.linalg.norm(diff)\n",
    "        \n",
    "        mse_loss = 1.0/n * np.sum(np.square(np.dot(X, theta) - y.reshape(-1,1)))\n",
    "\n",
    "        if verbose and i % (num_epochs/20) == 0:\n",
    "            print('Epoch {}, learning rate: {:.9f}, diff in theta (L2-norm): {:.6f}, mse_loss: {}.'.format(i, eta, l2ndiff, mse_loss))\n",
    "\n",
    "        if stop_fn is not None and stop_fn(diff):\n",
    "            if verbose:\n",
    "                print('Stop condition reached (iter {}).'.format(i))\n",
    "            break\n",
    "    \n",
    "    return theta.reshape(-1,), i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train the model for 250 epochs with a constant learning schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, learning rate: 0.050000000, diff in theta (L2-norm): 991.933466, mse_loss: 4043.8543881453734.\n",
      "Epoch 25, learning rate: 0.050000000, diff in theta (L2-norm): 0.006427, mse_loss: 4043.8532372394106.\n",
      "Epoch 50, learning rate: 0.050000000, diff in theta (L2-norm): 0.000461, mse_loss: 4043.8531591646356.\n",
      "Epoch 75, learning rate: 0.050000000, diff in theta (L2-norm): 0.000033, mse_loss: 4043.853153577898.\n",
      "Epoch 100, learning rate: 0.050000000, diff in theta (L2-norm): 0.000002, mse_loss: 4043.8531531769213.\n",
      "Epoch 125, learning rate: 0.050000000, diff in theta (L2-norm): 0.000000, mse_loss: 4043.853153148136.\n",
      "Epoch 150, learning rate: 0.050000000, diff in theta (L2-norm): 0.000000, mse_loss: 4043.85315314607.\n",
      "Epoch 175, learning rate: 0.050000000, diff in theta (L2-norm): 0.000000, mse_loss: 4043.8531531459225.\n",
      "Epoch 200, learning rate: 0.050000000, diff in theta (L2-norm): 0.000000, mse_loss: 4043.8531531459107.\n",
      "Epoch 225, learning rate: 0.050000000, diff in theta (L2-norm): 0.000000, mse_loss: 4043.8531531459093.\n"
     ]
    }
   ],
   "source": [
    "# use a lambda to define the constant schedule with the learning rate baked in\n",
    "learning_rate = 0.05\n",
    "lr_sched_fn = lambda i: constant_lr_schedule(learning_rate, i)\n",
    "\n",
    "theta, _ = stochastic_gradient_descent(X_with_b, train_y, gradient_mse, lr_sched_fn, num_epochs=250, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model -- w: [ 19.048  9.152 -10.044  37.807 -9.086  6.724 -34.405 -26.372  9.858\n",
      " -2.772 -9.309  20.558  1000.480 -12.950], b: 17.438\n",
      "Stochastic Gradient Descent model -- w: [ 15.338  37.772 -18.160  40.715 -16.616  17.116 -33.079 -32.488 -0.088\n",
      " -1.120 -9.666  19.246  988.051 -22.052], b: 26.900\n"
     ]
    }
   ],
   "source": [
    "b = theta[0]\n",
    "w = theta[1:]\n",
    "\n",
    "# Print the weights and bias for both models\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "print('Linear Regression model -- w: {}, b: {:.3f}'.format(lrmodel.coef_, lrmodel.intercept_))\n",
    "print('Stochastic Gradient Descent model -- w: {}, b: {:.3f}'.format(w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 2b] (10 points) Provide an explanation as to what is happening? Is the process converging? Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide an explanation as to what is happening? Is the process converging? Explain why.\n",
    "###* put your answer here *###\n",
    "#\n",
    "# Answer:\n",
    "# As the training goes on, the diff in theta gets smaller and smaller.\n",
    "# This reflects the learning curve gets flatter and flatter till the gradient becomes zero.\n",
    "# Besides, the mse_loss is getting smaller and smaller. \n",
    "# Above all, the process is converging.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 2c] (5 points) Train the model with a simple learning schedule that decreases the learning rate over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, learning rate: 0.000449256, diff in theta (L2-norm): 426.678924, mse_loss: 11436.507725385303.\n",
      "Epoch 25, learning rate: 0.000088744, diff in theta (L2-norm): 4.585235, mse_loss: 3718.4275761929603.\n",
      "Epoch 50, learning rate: 0.000063396, diff in theta (L2-norm): 1.355492, mse_loss: 3528.807843113005.\n",
      "Epoch 75, learning rate: 0.000051944, diff in theta (L2-norm): 0.570085, mse_loss: 3496.158550479286.\n",
      "Epoch 100, learning rate: 0.000045065, diff in theta (L2-norm): 0.284143, mse_loss: 3487.035672255372.\n",
      "Epoch 125, learning rate: 0.000040352, diff in theta (L2-norm): 0.157218, mse_loss: 3483.6444802007145.\n",
      "Epoch 150, learning rate: 0.000036863, diff in theta (L2-norm): 0.093529, mse_loss: 3482.100153627153.\n",
      "Epoch 175, learning rate: 0.000034146, diff in theta (L2-norm): 0.058732, mse_loss: 3481.27997501609.\n",
      "Epoch 200, learning rate: 0.000031954, diff in theta (L2-norm): 0.038475, mse_loss: 3480.7897966408245.\n",
      "Epoch 225, learning rate: 0.000030136, diff in theta (L2-norm): 0.026083, mse_loss: 3480.4690876819895.\n"
     ]
    }
   ],
   "source": [
    "# use a lambda to define a simple schedule that decreases the learning rate over time\n",
    "learning_rate = 0.05\n",
    "lr_sched_fn = lambda t: learning_rate / (1 + np.sqrt(t))\n",
    "\n",
    "# actually run the stochastic_gradient_descent for 250 epochs and store the result in 'theta'\n",
    "# make sure to use the simple learning schedule defined above (lr_sched_fn). Also set verbose=True\n",
    "###* put your code here (~1 line) *###\n",
    "theta, _ = stochastic_gradient_descent(X_with_b, train_y, gradient_mse, lr_sched_fn, num_epochs=250, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model -- w: [ 19.048  9.152 -10.044  37.807 -9.086  6.724 -34.405 -26.372  9.858\n",
      " -2.772 -9.309  20.558  1000.480 -12.950], b: 17.438\n",
      "Stochastic Gradient Descent model -- w: [ 17.572  10.939 -9.785  38.358 -11.518  6.767 -32.046 -26.476 -0.120\n",
      " -1.253 -5.755  21.941  995.004 -13.867], b: 14.914\n"
     ]
    }
   ],
   "source": [
    "b = theta[0]\n",
    "w = theta[1:]\n",
    "\n",
    "# Print the weights and bias for both models\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "print('Linear Regression model -- w: {}, b: {:.3f}'.format(lrmodel.coef_, lrmodel.intercept_))\n",
    "print('Stochastic Gradient Descent model -- w: {}, b: {:.3f}'.format(w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 2d] (10 points) Show that the model has similar performance as the linear regression model (lrmodel). For this, show the coefficient of determination, the RMSE, and the MedAE for both on the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Training R^2 score: 0.8940\n",
      "SGD Training MSE: 3480.25\n",
      "SGD Training MAE: 20.42\n",
      "SGD Validation R^2 score: 0.8843\n",
      "SGD Validation MSE: 3834.51\n",
      "SGD Validation MAE: 20.63\n",
      "Linear Regression Training R^2 score: 0.8942\n",
      "Linear Regression Training MSE: 3475.31\n",
      "Linear Regression Training MAE: 21.18\n",
      "Linear Regression Validation R^2 score: 0.8844\n",
      "Linear Regression Validation MSE: 3832.85\n",
      "Linear Regression Validation MAE: 21.18\n"
     ]
    }
   ],
   "source": [
    "# given model parameters 'theta' and a feature matrix 'x', this will return predictions\n",
    "def predict_theta(theta, x):\n",
    "    b = theta[0]\n",
    "    w = theta[1:]\n",
    "    \n",
    "    assert w.shape[0] == x.shape[1]\n",
    "    \n",
    "    return np.dot(w, x.T) + b\n",
    "    \n",
    "from sklearn.metrics import r2_score, mean_squared_error, median_absolute_error\n",
    "\n",
    "### You can implement this however you like. A simple way is to define a function to calculate and print \n",
    "### the scores and then call it for each model and dataset (train or val). For example, this function could have \n",
    "### the following signature: 'def print_scores(desc, true_y, pred_y):'\n",
    "### Hint: use predict_theta() for getting predictions from the model trained with SGD.\n",
    "###* put your code here (~7-10 lines) *###\n",
    "def print_scores(desc, true_y, pred_y):\n",
    "    r2Score = r2_score(true_y, pred_y)\n",
    "    print('{}R^2 score: {:.4f}'.format(desc, r2Score))\n",
    "    \n",
    "    mse_score = mean_squared_error(true_y, pred_y)\n",
    "    print('{}MSE: {:.2f}'.format(desc, mse_score))\n",
    "    \n",
    "    mae_score = median_absolute_error(true_y, pred_y)\n",
    "    print('{}MAE: {:.2f}'.format(desc, mae_score))\n",
    "\n",
    "print_scores(\"SGD Training \", train_y, predict_theta(theta, train_x))\n",
    "print_scores(\"SGD Validation \", val_y, predict_theta(theta, val_x))\n",
    "\n",
    "print_scores(\"Linear Regression Training \", train_y, lrmodel.predict(train_x))\n",
    "print_scores(\"Linear Regression Validation \", val_y, lrmodel.predict(val_x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 3] (20 points) Mini-Batch Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3a] (5 points) Complete the implementation of mini_batch_sgd to include a callback after each epoch. This callback will be useful to obtain information during the optimization process. If the callback function is defined, your code should call it with the proper arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_sgd(X, y, gradient_fn, lr_schedule_fn, num_epochs=1000, batch_size=100, callback_fn=None, stop_fn=None, verbose=False):\n",
    "    \n",
    "    (n, m) = X.shape\n",
    "    theta = np.random.uniform(low=-1.0, high=1.0, size=(X.shape[1],1)) # initialize uniformly at random in [-1, 1]\n",
    "    \n",
    "    batch_size = np.minimum(n, batch_size)\n",
    "    \n",
    "    for epoch in range(0, num_epochs):\n",
    "        prev_theta = theta\n",
    "\n",
    "        # shuffle the data\n",
    "        pi = np.random.permutation(n)\n",
    "        Xshuf = X[pi,:]\n",
    "        yshuf = y[pi]\n",
    "        for batch_start in range(0, n, batch_size):\n",
    "            \n",
    "            batch_idx = batch_start/batch_size\n",
    "            bsidx = batch_start\n",
    "            beidx = np.minimum(n, bsidx + batch_size)\n",
    "            Xmb = Xshuf[bsidx:beidx,:]\n",
    "            ymb = yshuf[bsidx:beidx]\n",
    "            \n",
    "            eta = lr_schedule_fn(epoch*n + bsidx)\n",
    "            \n",
    "            # grab gradient vector\n",
    "            gradient = gradient_fn(Xmb, ymb, theta)\n",
    "            assert gradient.shape == theta.shape  \n",
    "            \n",
    "            # update theta (actual gradient descent step)\n",
    "            theta = theta - eta * gradient\n",
    "            \n",
    "        \n",
    "        ### If callback_fn is defined (not None), call it and pass it the current epoch and current set of parameters\n",
    "        ###* put your code here (~2 lines) *###\n",
    "        if callback_fn is not None:\n",
    "            callback_fn(epoch, theta)\n",
    "        \n",
    "\n",
    "        # compute diff \n",
    "        diff = theta - prev_theta\n",
    "        l2ndiff = np.linalg.norm(diff)\n",
    "\n",
    "        if verbose and epoch % (num_epochs/20) == 0:\n",
    "            print('Epoch {}, learning rate: {:.9f}, diff in theta (L2-norm): {:.6f}.'.format(epoch, eta, l2ndiff))\n",
    "\n",
    "        if stop_fn is not None and stop_fn(diff):\n",
    "            if verbose:\n",
    "                print('Stop condition reached (iter {}).'.format(i))\n",
    "            break\n",
    "            \n",
    "    return theta.reshape(-1,), epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3b] (5 points) Fill in the implementation of the callback function to save the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's use the following plotting function to explore our loss during gradient descent\n",
    "def plot_process_data(proc_data, ylabel, xlim=None, ylim=None):\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    plt.plot(np.arange(proc_data.shape[0]), proc_data[:,0], 'b--', linewidth=3, label='Training')\n",
    "    plt.plot(np.arange(proc_data.shape[0]), proc_data[:,1], 'r:', linewidth=3, label='Validation')\n",
    "\n",
    "    plt.legend()\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# This will be our callback function. \n",
    "# After each epoch, this function gets called so we can check on the progress of gradient descent\n",
    "# We'll save the RMSE for both train and val in the 'rmse' array so we can plot it later\n",
    "def rmse_per_epoch(epoch, theta, rmse, train_x, train_y, val_x, val_y):\n",
    "    theta = theta.reshape(-1,)\n",
    "    pred_y = predict_theta(theta, train_x)\n",
    "    \n",
    "    ### compute the RMSE on the training data, store the result in 'rmse[epoch, 0]'\n",
    "    ###* put your code here (~2 lines) *###\n",
    "    mse_score_train = mean_squared_error(train_y, pred_y)\n",
    "    rmse[epoch, 0] = mse_score_train\n",
    "    \n",
    "    pred_y = predict_theta(theta, val_x)\n",
    "    \n",
    "    ### compute the RMSE on the validation data, store the result in 'rmse[epoch, 1]'\n",
    "    ###* put your code here (~2 lines) *###\n",
    "    mse_score_val = mean_squared_error(val_y, pred_y)\n",
    "    rmse[epoch, 1] = mse_score_val\n",
    "\n",
    "# params for gradient descent\n",
    "num_epochs = 500\n",
    "bsz = 100\n",
    "\n",
    "# define our array to store the rmse_data. One row per epoch, column 0 will be train, column 1 will be val.\n",
    "rmse_data = np.zeros((num_epochs,2))\n",
    "\n",
    "# define the callback function\n",
    "ecbfn = lambda i, t : rmse_per_epoch(i, t, rmse_data, train_x, train_y, val_x, val_y)\n",
    "\n",
    "# use a lambda to define a simple schedule that decreases the learning rate slowly over time\n",
    "learning_rate = 0.05\n",
    "lr_sched_fn = lambda t: learning_rate / (1 + np.log(1 + t)) \n",
    "\n",
    "theta, _ = mini_batch_sgd(X_with_b, train_y, grad_fn, lr_sched_fn, \n",
    "                          num_epochs=num_epochs, batch_size=bsz, callback_fn=ecbfn, verbose=False)\n",
    "\n",
    "# do the actual plotting\n",
    "plot_process_data(rmse_data, 'RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3c] (5 points) Does the process converge? Should the number of epochs be increased? What about the learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "# Answer:\n",
    "# We can see that the learning curve gose flat since 200 epochs. \n",
    "# Therefor, the process converges. The number of epochs should not be increased.\n",
    "# By the learning curve the schedled learning rate works well in this model, since it is not learning too slow or \n",
    "# not converging.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3d] (10 points) What do you conclude? Is it worth training a linear regression model this way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miniBatch_SGD Training R^2 score: 0.8942\n",
      "miniBatch_SGD Training MSE: 3476.19\n",
      "miniBatch_SGD Training MAE: 20.85\n",
      "miniBatch_SGD Validation R^2 score: 0.8844\n",
      "miniBatch_SGD Validation MSE: 3832.08\n",
      "miniBatch_SGD Validation MAE: 20.89\n",
      "Linear Regression Training R^2 score: 0.8942\n",
      "Linear Regression Training MSE: 3475.31\n",
      "Linear Regression Training MAE: 21.18\n",
      "Linear Regression Validation R^2 score: 0.8844\n",
      "Linear Regression Validation MSE: 3832.85\n",
      "Linear Regression Validation MAE: 21.18\n"
     ]
    }
   ],
   "source": [
    "print_scores(\"miniBatch_SGD Training \", train_y, predict_theta(theta, train_x))\n",
    "print_scores(\"miniBatch_SGD Validation \", val_y, predict_theta(theta, val_x))\n",
    "\n",
    "print_scores(\"Linear Regression Training \", train_y, lrmodel.predict(train_x))\n",
    "print_scores(\"Linear Regression Validation \", val_y, lrmodel.predict(val_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "# I think it is not worth trining a liner regression model this way(with gradient descent).\n",
    "# Because compared to Linear Regression model, Gradient Decent model is more time consuming\n",
    "# while has a similar performance.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 4] (10 points) Use SGDRegressor to train a similar that you did in Task 3. Show that the performance of both models is comparable (show R^2, RMSE, MedAE for both train and val). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miniBatch_SGD Training R^2 score: 0.8942\n",
      "miniBatch_SGD Training MSE: 3476.19\n",
      "miniBatch_SGD Training MAE: 20.85\n",
      "miniBatch_SGD Validation R^2 score: 0.8844\n",
      "miniBatch_SGD Validation MSE: 3832.08\n",
      "miniBatch_SGD Validation MAE: 20.89\n",
      "SGDRegressor Training R^2 score: 0.8942\n",
      "SGDRegressor Training MSE: 3476.37\n",
      "SGDRegressor Training MAE: 21.02\n",
      "SGDRegressor Validation R^2 score: 0.8845\n",
      "SGDRegressor Validation MSE: 3830.72\n",
      "SGDRegressor Validation MAE: 21.18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "### Tip: if you defined a print_scores() method for Task 2d, you can reuse it here!\n",
    "###* put your code here (~5 lines) *###\n",
    "sgdr_model = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "sgdr_model.fit(train_x, train_y)\n",
    "sgdr_model.score(val_x, val_y)\n",
    "\n",
    "print_scores(\"miniBatch_SGD Training \", train_y, predict_theta(theta, train_x))\n",
    "print_scores(\"miniBatch_SGD Validation \", val_y, predict_theta(theta, val_x))\n",
    "\n",
    "print_scores(\"SGDRegressor Training \", train_y, sgdr_model.predict(train_x))\n",
    "print_scores(\"SGDRegressor Validation \", val_y, sgdr_model.predict(val_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CIS6930 Additional Task -- Task 5] (25 points): Ridge Regression with Mini-batch SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this task, you will implement ridge regression using mini-batch SGD as defined in Task 3. \n",
    "### The main task is to derive the gradient vector for Ridge Regression (L2 regularization with MSE as loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5a] (15 points) Implement the gradient_mse_ridge() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_mse_ridge(X, y, theta, lmbda):\n",
    "    (n, m) = X.shape\n",
    "    \n",
    "    y = y.reshape(-1,1)\n",
    "    assert y.shape == (n,1)\n",
    "    assert theta.shape == (m,1)\n",
    "    \n",
    "    ### Figure out the gradient for ridge regression and implement this function \n",
    "    ### (You can refer to the course slides: lecture 5 on linear models, slide 12.)\n",
    "    ### Note 1: use 'lmbda' (lambda) -- the regularization hyperparameter.\n",
    "    ### Note 2: normally we do not regularize the bias term b, but if you cannot avoid it is acceptable to regularize it for this task.\n",
    "    ###* put your code here (~1-4 lines) *###\n",
    "    \n",
    "    return 2.0/n * np.dot(X.T, (np.dot(X, theta) - y)) + 2.0 * lmbda * theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's put some code to do the mini-batch sgd ridge regression training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mbsgd_ridge(lmbda):\n",
    "    num_epochs = 1000\n",
    "    bsz = 100\n",
    "\n",
    "    rmse_data = np.zeros((num_epochs,2))\n",
    "\n",
    "    # define the callback function\n",
    "    ecbfn = lambda i, t : rmse_per_epoch(i, t, rmse_data, train_x, train_y, val_x, val_y)\n",
    "\n",
    "    # use a lambda to define a simple schedule that decreases the learning rate over time\n",
    "    learning_rate = 0.05\n",
    "    lr_sched_fn = lambda t: learning_rate / (1 + np.log(1 + t))\n",
    "\n",
    "    # bake in lambda into the gradient fn\n",
    "    grad_fn = lambda X, y, thet : gradient_mse_ridge(X, y, thet, lmbda)\n",
    "\n",
    "    theta, _ = mini_batch_sgd(X_with_b, train_y, grad_fn, lr_sched_fn, \n",
    "                              num_epochs=num_epochs, batch_size=bsz, callback_fn=ecbfn, verbose=False)\n",
    "\n",
    "    # do the actual plotting\n",
    "    plot_process_data(rmse_data, 'RMSE')\n",
    "\n",
    "    ### if you have defined print_scores above, you can uncomment the following lines.\n",
    "    #print_scores('SGD (Manual) Train', train_y, predict_theta(theta, train_x))\n",
    "    #print_scores('SGD (Manual) Val', val_y, predict_theta(theta, val_x))\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5b] (5 points) In theory, what is the effect of L2 regularization on the weights vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "# The effect of L2 regularization is to apply penalty over the weights vector to make the weights of the medel small.\n",
    "# It can prevent the model from learning any complext concept with respect to any particular feature,\n",
    "# thereby preventing overfitting.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5c] (5 points) Run mini-batch SGD for Ridge regression using whatever value of lambda you think is appropriate. Make sure that the process stills converges and that you end up with a model with a comparable performance to the ones you trained in previous tasks (but that still shows some effect from L2 regularization). Show the effect of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model -- w: [ 19.048  9.152 -10.044  37.807 -9.086  6.724 -34.405 -26.372  9.858\n",
      " -2.772 -9.309  20.558  1000.480 -12.950], b: 17.438\n",
      "Mini-batch SGD Ridge -- w: [ 19.376  9.500 -10.004  38.718 -9.081  6.761 -34.125 -26.644  0.532\n",
      " -0.996 -9.398  20.912  995.766 -12.953], b: 17.193\n",
      "\n",
      "miniBatch_SGD Training R^2 score: 0.8942\n",
      "miniBatch_SGD Training MSE: 3475.51\n",
      "miniBatch_SGD Training MAE: 21.23\n",
      "miniBatch_SGD Validation R^2 score: 0.8844\n",
      "miniBatch_SGD Validation MSE: 3833.29\n",
      "miniBatch_SGD Validation MAE: 21.32\n",
      "Mini-batch SGD Ridge Training R^2 score: 0.8942\n",
      "Mini-batch SGD Ridge Training MSE: 3475.78\n",
      "Mini-batch SGD Ridge Training MAE: 21.16\n",
      "Mini-batch SGD Ridge Validation R^2 score: 0.8844\n",
      "Mini-batch SGD Ridge Validation MSE: 3831.60\n",
      "Mini-batch SGD Ridge Validation MAE: 21.20\n"
     ]
    }
   ],
   "source": [
    "###* put your code here (~1 line) to set the value of lambda ('lmbda') *###\n",
    "lmbda = 0.0001\n",
    "\n",
    "\n",
    "theta = do_mbsgd_ridge(lmbda)\n",
    "\n",
    "b = theta[0]\n",
    "w = theta[1:]\n",
    "\n",
    "print('Linear Regression model -- w: {}, b: {:.3f}'.format(lrmodel.coef_, lrmodel.intercept_))\n",
    "print('Mini-batch SGD Ridge -- w: {}, b: {:.3f}\\n'.format(w, b))\n",
    "\n",
    "\n",
    "###* put your code/answer here *###\n",
    "#\n",
    "# Answer:\n",
    "# As the results showed below, with a lamba of 0.0001, the mini-batch SGD for Ridge regression gets\n",
    "# a better performance than the normal mini-batch SGD model trained for the task 3 in the sense of MSE and MAE.\n",
    "\n",
    "learning_rate = 0.05\n",
    "lr_sched_fn = lambda t: learning_rate / (1 + np.log(1 + t)) \n",
    "\n",
    "theta_normal, _ = mini_batch_sgd(X_with_b, train_y, grad_fn, lr_sched_fn, \n",
    "                          num_epochs=num_epochs, batch_size=bsz, callback_fn=ecbfn, verbose=False)\n",
    "\n",
    "print_scores(\"miniBatch_SGD Training \", train_y, predict_theta(theta_normal, train_x))\n",
    "print_scores(\"miniBatch_SGD Validation \", val_y, predict_theta(theta_normal, val_x))\n",
    "\n",
    "print_scores(\"Mini-batch SGD Ridge Training \", train_y, predict_theta(theta, train_x))\n",
    "print_scores(\"Mini-batch SGD Ridge Validation \", val_y, predict_theta(theta, val_x))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
